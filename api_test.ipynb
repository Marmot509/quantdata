{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stock_margin_szse() got an unexpected keyword argument 'start_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01makshare\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mak\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sz_margin1 \u001b[38;5;241m=\u001b[39m \u001b[43mak\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstock_margin_szse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m20160101\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m20240208\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sz_margin1)\n",
      "\u001b[0;31mTypeError\u001b[0m: stock_margin_szse() got an unexpected keyword argument 'start_date'"
     ]
    }
   ],
   "source": [
    "import akshare as ak\n",
    "sz_margin1 = ak.stock_margin_szse()\n",
    "print(sz_margin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  open  high   low  close      volume       amount  \\\n",
      "0   2020-01-02  2.95  2.99  2.94   2.97  36871604.0  109486236.0   \n",
      "1   2020-01-03  2.98  3.02  2.95   3.00  27818004.0   82999342.0   \n",
      "2   2020-01-06  2.97  3.02  2.95   3.02  33257784.0   99700380.0   \n",
      "3   2020-01-07  3.02  3.07  3.00   3.06  37977145.0  115346273.0   \n",
      "4   2020-01-08  3.04  3.05  2.98   3.00  31095373.0   93753675.0   \n",
      "5   2020-01-09  3.01  3.05  3.01   3.03  24666225.0   74623391.0   \n",
      "6   2020-01-10  3.03  3.05  2.99   3.01  22650900.0   68354381.0   \n",
      "7   2020-01-13  3.00  3.02  2.96   3.02  22747101.0   68041901.0   \n",
      "8   2020-01-14  3.02  3.04  2.99   3.00  30327650.0   91476304.0   \n",
      "9   2020-01-15  3.00  3.00  2.94   2.95  25401675.0   75167452.0   \n",
      "10  2020-01-16  2.97  2.98  2.92   2.93  24142513.0   71073718.0   \n",
      "11  2020-01-17  2.93  2.95  2.88   2.89  23314487.0   67963883.0   \n",
      "12  2020-01-20  2.88  2.92  2.84   2.91  22584233.0   65234809.0   \n",
      "13  2020-01-21  2.89  2.90  2.85   2.86  19968404.0   57228468.0   \n",
      "14  2020-01-22  2.85  2.89  2.80   2.88  22055335.0   62672290.0   \n",
      "15  2020-01-23  2.90  3.01  2.87   2.93  59113735.0  173828551.0   \n",
      "\n",
      "    outstanding_share  turnover  \n",
      "0        2.573189e+09  0.014329  \n",
      "1        2.573189e+09  0.010811  \n",
      "2        2.573189e+09  0.012925  \n",
      "3        2.573189e+09  0.014759  \n",
      "4        2.573189e+09  0.012084  \n",
      "5        2.573189e+09  0.009586  \n",
      "6        2.573189e+09  0.008803  \n",
      "7        2.573189e+09  0.008840  \n",
      "8        2.573189e+09  0.011786  \n",
      "9        2.573189e+09  0.009872  \n",
      "10       2.573189e+09  0.009382  \n",
      "11       2.573189e+09  0.009061  \n",
      "12       2.573189e+09  0.008777  \n",
      "13       2.573189e+09  0.007760  \n",
      "14       2.573189e+09  0.008571  \n",
      "15       2.573189e+09  0.022973  \n"
     ]
    }
   ],
   "source": [
    "testdata2 = akshare.stock_zh_a_daily(symbol='sh600751', start_date='20200101', end_date='20200131', adjust=\"qfq\")  \n",
    "print(testdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date            qfq_factor\n",
      "0  2023-08-25    1.0000000000000000\n",
      "1  2022-08-25    1.0517754291451000\n",
      "2  2021-08-25    1.1168798473057000\n",
      "3  2020-08-14    1.1810093745970000\n",
      "4  2019-08-15    1.2245366427798000\n",
      "5  2018-08-23    1.2735981991808000\n",
      "6  2017-08-29    1.3233913520593000\n",
      "7  2016-07-29    1.3684162947004000\n",
      "8  2015-07-21    1.4256988372693000\n",
      "9  2014-05-08    1.4737021651235000\n",
      "10 2013-05-16    1.5546965200431000\n",
      "11 2012-07-05    1.5798398599899000\n",
      "12 2011-05-27    1.6027105929296000\n",
      "13 2010-05-18    1.6232581646338000\n",
      "14 2009-06-08    1.6398462042724000\n",
      "15 2008-06-16    1.6475522484654000\n",
      "16 2007-05-16    2.6521572780175000\n",
      "17 2006-07-21    4.0043855834397000\n",
      "18 2005-06-29    4.1056769557021000\n",
      "19 2004-05-26    6.3462750504298000\n",
      "20 2003-05-23    9.5848830885446000\n",
      "21 2002-07-17   19.4514673699928000\n",
      "22 2001-08-21   19.7687833140383020\n",
      "23 2000-08-17   20.0160648287379000\n",
      "24 2000-01-10   20.2241320306998030\n",
      "25 1999-08-06   21.7007260053956000\n",
      "26 1998-07-10   24.0549868667835000\n",
      "27 1997-07-14   26.7769985385511000\n",
      "28 1997-06-27   31.2296603923877000\n",
      "29 1996-08-06   36.0689784010141000\n",
      "30 1995-07-04   40.3371408451341000\n",
      "31 1994-06-21   47.9136235499274000\n",
      "32 1993-04-05   65.9178076663026900\n",
      "33 1992-03-30   99.0712868582592000\n",
      "34 1991-06-10  118.8855442299110900\n",
      "35 1991-01-29  169.1453113717332000\n",
      "36 1900-01-01  169.1453113717332000\n"
     ]
    }
   ],
   "source": [
    "import akshare as ak\n",
    "\n",
    "qfq_factor_df = ak.stock_zh_a_daily(symbol=\"sz000002\", adjust=\"qfq-factor\")\n",
    "print(qfq_factor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    序号        品种\n",
      "0    1   Au99.99\n",
      "1    2   Au99.95\n",
      "2    3    Au100g\n",
      "3    4   Pt99.95\n",
      "4    5   Ag(T+D)\n",
      "5    6   Au(T+D)\n",
      "6    7  mAu(T+D)\n",
      "7    8  Au(T+N1)\n",
      "8    9  Au(T+N2)\n",
      "9   10   Ag99.99\n",
      "10  11  iAu99.99\n",
      "11  12    Au99.5\n",
      "12  13   iAu100g\n",
      "13  14   iAu99.5\n",
      "14  15    PGC30g\n",
      "15  16  NYAuTN06\n",
      "16  17  NYAuTN12\n"
     ]
    }
   ],
   "source": [
    "print(ak.spot_symbol_table_sge() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   融资买入额     融资余额  融券卖出量   融券余量    融券余额   融资融券余额\n",
      "0  267.8  7113.05   0.93  31.99  579.71  7692.76\n"
     ]
    }
   ],
   "source": [
    "import akshare as ak\n",
    "\n",
    "stock_margin_sse_df = ak.stock_margin_szse(date=\"20210401\")\n",
    "print(stock_margin_sse_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top market cap stocks 2005换手率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import akshare as ak\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm  # Import the tqdm module\n",
    "\n",
    "# def check_ticker_file_exists(ticker, folder_path):\n",
    "#     # 检查两种前缀\n",
    "#     prefixes = ['sh', 'sz']\n",
    "#     for prefix in prefixes:\n",
    "#         file_name = f\"{prefix}{ticker}.csv\"\n",
    "#         file_path = os.path.join(folder_path, file_name)\n",
    "#         if os.path.isfile(file_path):\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "# # read data from file\n",
    "# # with open('stock_data/top_cap_tickers.json') as f:\n",
    "# #     tickers = json.load(f)\n",
    "\n",
    "# # Read the JSON data from the file\n",
    "# try:\n",
    "#     with open('stock_data/top_cap_tickers.json') as f:\n",
    "#         tickers = json.load(f)\n",
    "# except json.JSONDecodeError as e:\n",
    "#     print(f\"JSON decode error: {e}\")\n",
    "#     # Handle the error, e.g., by logging or raising an exception\n",
    "# except FileNotFoundError as e:\n",
    "#     print(f\"File not found: {e}\")\n",
    "#     # Handle the file not being found\n",
    "# except Exception as e:\n",
    "#     print(f\"An unexpected error occurred: {e}\")\n",
    "#     # Handle any other exception that might occur\n",
    "\n",
    "# baf_path = 'stock_data/data/backward_adjust_factor/'\n",
    "\n",
    "# # get data from akshare api and save it to a dataframe with the ticker as the index and the turnover_ratio, market_cap and circulating_market_cap as columns\n",
    "# columns = ['tickers', 'turnover_ratio', 'market_cap', 'circulating_market_cap']\n",
    "# df = pd.DataFrame(columns=columns)\n",
    "# df.set_index('tickers', inplace=True)\n",
    "\n",
    "# for ticker in tqdm(tickers, desc=\"Processing tickers\"):\n",
    "#     if check_ticker_file_exists(ticker, baf_path):\n",
    "#         turnover = ak.stock_zh_a_hist(symbol=ticker, start_date='20050104', end_date='20051230', adjust='')[['换手率']]\n",
    "#         daily_average_turnover = turnover['换手率'].mean() / 100\n",
    "#         df.loc[ticker, 'turnover_ratio'] = daily_average_turnover\n",
    "\n",
    "#         amount = ak.stock_zh_a_hist(symbol=ticker, start_date='20050104', end_date='20051230', adjust='')[['成交额']]\n",
    "#         circulating_market_cap = amount['成交额'].iloc[-1] / turnover['换手率'].iloc[-1] * 100\n",
    "#         df.loc[ticker, 'circulating_market_cap'] = circulating_market_cap\n",
    "#     else:\n",
    "#         print(f\"Error: Ticker file for {ticker} does not exist in the folder {baf_path}.\")\n",
    "\n",
    "# # sort the dataframe by the turnover_ratio from highest to lowest\n",
    "# df.sort_values(by='turnover_ratio', ascending=False, inplace=True)\n",
    "\n",
    "# # save the dataframe to a csv file\n",
    "# df.to_csv('turnovers.csv') \n",
    "# df.to_pickle('turnovers.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all stocks 2005换手率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers: 100%|██████████| 5100/5100 [54:47<00:00,  1.55it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2000 saved to turnovers_2000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers: 100%|██████████| 5100/5100 [1:06:47<00:00,  1.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2005 saved to turnovers_2005.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers: 100%|██████████| 5100/5100 [46:22<00:00,  1.83it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2010 saved to turnovers_2010.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import akshare as ak\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_stock_data(year):\n",
    "    # Read the JSON data from the file\n",
    "    try:\n",
    "        with open('stock_data/tickers.json') as f:\n",
    "            tickers = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decode error: {e}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    # Prepare start and end dates based on the input year\n",
    "    start_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    # Prepare dataframe\n",
    "    columns = ['tickers', 'turnover_ratio', 'market_cap', 'circulating_market_cap', 'trading_days']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    df.set_index('tickers', inplace=True)\n",
    "\n",
    "    for ticker in tqdm(tickers, desc=\"Processing tickers\"):\n",
    "        try:\n",
    "            # Fetch data from akshare for the given dates\n",
    "            turnover = ak.stock_zh_a_hist(symbol=ticker, start_date=start_date, end_date=end_date, adjust='')[['换手率']]\n",
    "            trading_days = len(turnover)\n",
    "            daily_average_turnover = turnover['换手率'].mean() / 100\n",
    "            df.loc[ticker, 'turnover_ratio'] = daily_average_turnover\n",
    "\n",
    "            amount = ak.stock_zh_a_hist(symbol=ticker, start_date=start_date, end_date=end_date, adjust='')[['成交额']]\n",
    "            circulating_market_cap = amount['成交额'].iloc[-1] / turnover['换手率'].iloc[-1] * 100\n",
    "            df.loc[ticker, 'circulating_market_cap'] = circulating_market_cap\n",
    "\n",
    "            # Add trading days to the dataframe\n",
    "            df.loc[ticker, 'trading_days'] = trading_days\n",
    "\n",
    "        except Exception as e:\n",
    "            df.loc[ticker, ['turnover_ratio', 'circulating_market_cap', 'trading_days']] = [np.nan, np.nan, np.nan]\n",
    "\n",
    "    # Sort and save the dataframe\n",
    "    df.sort_values(by='turnover_ratio', ascending=False, inplace=True)\n",
    "    filename = f'turnovers_{year}.csv'\n",
    "    df.to_csv(filename)\n",
    "    df.to_pickle(f'turnovers_{year}.pkl')\n",
    "    print(f\"Data for {year} saved to {filename}\")\n",
    "\n",
    "years = [2000, 2005, 2010]\n",
    "for year in years:\n",
    "    process_stock_data(year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 'turnovers_2000.csv' to PKL format.\n",
      "Converted 'turnovers_2005.csv' to PKL format.\n",
      "Converted 'turnovers_2010.csv' to PKL format.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def convert_csv_to_pkl(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_path = os.path.join(folder_path, filename)\n",
    "            pkl_path = os.path.join(folder_path, filename.replace('.csv', '.pkl'))\n",
    "\n",
    "            # 读取CSV文件\n",
    "            df = pd.read_csv(csv_path)\n",
    "\n",
    "            # 将DataFrame保存为PKL文件\n",
    "            df.to_pickle(pkl_path)\n",
    "            print(f\"Converted '{filename}' to PKL format.\")\n",
    "\n",
    "# 定义包含CSV文件的文件夹路径\n",
    "folder_path = '.'\n",
    "\n",
    "# 转换文件夹内的所有CSV文件为PKL\n",
    "convert_csv_to_pkl(folder_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
