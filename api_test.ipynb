{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stock_margin_szse() got an unexpected keyword argument 'start_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01makshare\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mak\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sz_margin1 \u001b[38;5;241m=\u001b[39m \u001b[43mak\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstock_margin_szse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m20160101\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m20240208\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sz_margin1)\n",
      "\u001b[0;31mTypeError\u001b[0m: stock_margin_szse() got an unexpected keyword argument 'start_date'"
     ]
    }
   ],
   "source": [
    "import akshare as ak\n",
    "sz_margin1 = ak.stock_margin_szse()\n",
    "print(sz_margin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  open  high   low  close      volume       amount  \\\n",
      "0   2020-01-02  2.95  2.99  2.94   2.97  36871604.0  109486236.0   \n",
      "1   2020-01-03  2.98  3.02  2.95   3.00  27818004.0   82999342.0   \n",
      "2   2020-01-06  2.97  3.02  2.95   3.02  33257784.0   99700380.0   \n",
      "3   2020-01-07  3.02  3.07  3.00   3.06  37977145.0  115346273.0   \n",
      "4   2020-01-08  3.04  3.05  2.98   3.00  31095373.0   93753675.0   \n",
      "5   2020-01-09  3.01  3.05  3.01   3.03  24666225.0   74623391.0   \n",
      "6   2020-01-10  3.03  3.05  2.99   3.01  22650900.0   68354381.0   \n",
      "7   2020-01-13  3.00  3.02  2.96   3.02  22747101.0   68041901.0   \n",
      "8   2020-01-14  3.02  3.04  2.99   3.00  30327650.0   91476304.0   \n",
      "9   2020-01-15  3.00  3.00  2.94   2.95  25401675.0   75167452.0   \n",
      "10  2020-01-16  2.97  2.98  2.92   2.93  24142513.0   71073718.0   \n",
      "11  2020-01-17  2.93  2.95  2.88   2.89  23314487.0   67963883.0   \n",
      "12  2020-01-20  2.88  2.92  2.84   2.91  22584233.0   65234809.0   \n",
      "13  2020-01-21  2.89  2.90  2.85   2.86  19968404.0   57228468.0   \n",
      "14  2020-01-22  2.85  2.89  2.80   2.88  22055335.0   62672290.0   \n",
      "15  2020-01-23  2.90  3.01  2.87   2.93  59113735.0  173828551.0   \n",
      "\n",
      "    outstanding_share  turnover  \n",
      "0        2.573189e+09  0.014329  \n",
      "1        2.573189e+09  0.010811  \n",
      "2        2.573189e+09  0.012925  \n",
      "3        2.573189e+09  0.014759  \n",
      "4        2.573189e+09  0.012084  \n",
      "5        2.573189e+09  0.009586  \n",
      "6        2.573189e+09  0.008803  \n",
      "7        2.573189e+09  0.008840  \n",
      "8        2.573189e+09  0.011786  \n",
      "9        2.573189e+09  0.009872  \n",
      "10       2.573189e+09  0.009382  \n",
      "11       2.573189e+09  0.009061  \n",
      "12       2.573189e+09  0.008777  \n",
      "13       2.573189e+09  0.007760  \n",
      "14       2.573189e+09  0.008571  \n",
      "15       2.573189e+09  0.022973  \n"
     ]
    }
   ],
   "source": [
    "testdata2 = akshare.stock_zh_a_daily(symbol='sh600751', start_date='20200101', end_date='20200131', adjust=\"qfq\")  \n",
    "print(testdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date           qfq_factor\n",
      "0  2023-06-21   1.0000000000000000\n",
      "1  2022-06-24   1.0370370370370000\n",
      "2  2021-06-22   1.0795385549484000\n",
      "3  2020-06-23   1.1247706173066000\n",
      "4  2019-06-28   1.1802691675026000\n",
      "5  2018-06-22   1.2222911347666000\n",
      "6  2017-07-14   1.2297441294908000\n",
      "7  2016-07-08   1.2347295786644000\n",
      "8  2015-05-29   1.2758491576024000\n",
      "9  2014-06-12   1.2773507454693000\n",
      "10 2013-06-14   1.2850148499421000\n",
      "11 2012-05-25   1.2986561965445000\n",
      "12 2011-04-14   1.3357077285429000\n",
      "13 2010-04-27   1.3886070445248000\n",
      "14 2009-04-30   2.3667603037703000\n",
      "15 2007-08-27   3.1264540671354000\n",
      "16 2007-05-29   6.2668993514276000\n",
      "17 2006-04-21   6.2717367882098000\n",
      "18 2006-01-25   7.5624726123968000\n",
      "19 2005-05-27   9.8312143961158000\n",
      "20 1998-04-27  12.9158229341564000\n",
      "21 1997-06-25  20.6653166946503000\n",
      "22 1997-03-06  27.6192180791568000\n",
      "23 1900-01-01  27.6192180791568000\n"
     ]
    }
   ],
   "source": [
    "import akshare as ak\n",
    "\n",
    "qfq_factor_df = ak.stock_zh_a_daily(symbol=\"sz001696\", adjust=\"qfq-factor\")\n",
    "print(qfq_factor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    序号        品种\n",
      "0    1   Au99.99\n",
      "1    2   Au99.95\n",
      "2    3    Au100g\n",
      "3    4   Pt99.95\n",
      "4    5   Ag(T+D)\n",
      "5    6   Au(T+D)\n",
      "6    7  mAu(T+D)\n",
      "7    8  Au(T+N1)\n",
      "8    9  Au(T+N2)\n",
      "9   10   Ag99.99\n",
      "10  11  iAu99.99\n",
      "11  12    Au99.5\n",
      "12  13   iAu100g\n",
      "13  14   iAu99.5\n",
      "14  15    PGC30g\n",
      "15  16  NYAuTN06\n",
      "16  17  NYAuTN12\n"
     ]
    }
   ],
   "source": [
    "print(ak.spot_symbol_table_sge() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   融资买入额     融资余额  融券卖出量   融券余量    融券余额   融资融券余额\n",
      "0  267.8  7113.05   0.93  31.99  579.71  7692.76\n"
     ]
    }
   ],
   "source": [
    "import akshare as ak\n",
    "\n",
    "stock_margin_sse_df = ak.stock_margin_szse(date=\"20210401\")\n",
    "print(stock_margin_sse_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top market cap stocks 2005换手率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import akshare as ak\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm  # Import the tqdm module\n",
    "\n",
    "# def check_ticker_file_exists(ticker, folder_path):\n",
    "#     # 检查两种前缀\n",
    "#     prefixes = ['sh', 'sz']\n",
    "#     for prefix in prefixes:\n",
    "#         file_name = f\"{prefix}{ticker}.csv\"\n",
    "#         file_path = os.path.join(folder_path, file_name)\n",
    "#         if os.path.isfile(file_path):\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "# # read data from file\n",
    "# # with open('stock_data/top_cap_tickers.json') as f:\n",
    "# #     tickers = json.load(f)\n",
    "\n",
    "# # Read the JSON data from the file\n",
    "# try:\n",
    "#     with open('stock_data/top_cap_tickers.json') as f:\n",
    "#         tickers = json.load(f)\n",
    "# except json.JSONDecodeError as e:\n",
    "#     print(f\"JSON decode error: {e}\")\n",
    "#     # Handle the error, e.g., by logging or raising an exception\n",
    "# except FileNotFoundError as e:\n",
    "#     print(f\"File not found: {e}\")\n",
    "#     # Handle the file not being found\n",
    "# except Exception as e:\n",
    "#     print(f\"An unexpected error occurred: {e}\")\n",
    "#     # Handle any other exception that might occur\n",
    "\n",
    "# baf_path = 'stock_data/data/backward_adjust_factor/'\n",
    "\n",
    "# # get data from akshare api and save it to a dataframe with the ticker as the index and the turnover_ratio, market_cap and circulating_market_cap as columns\n",
    "# columns = ['tickers', 'turnover_ratio', 'market_cap', 'circulating_market_cap']\n",
    "# df = pd.DataFrame(columns=columns)\n",
    "# df.set_index('tickers', inplace=True)\n",
    "\n",
    "# for ticker in tqdm(tickers, desc=\"Processing tickers\"):\n",
    "#     if check_ticker_file_exists(ticker, baf_path):\n",
    "#         turnover = ak.stock_zh_a_hist(symbol=ticker, start_date='20050104', end_date='20051230', adjust='')[['换手率']]\n",
    "#         daily_average_turnover = turnover['换手率'].mean() / 100\n",
    "#         df.loc[ticker, 'turnover_ratio'] = daily_average_turnover\n",
    "\n",
    "#         amount = ak.stock_zh_a_hist(symbol=ticker, start_date='20050104', end_date='20051230', adjust='')[['成交额']]\n",
    "#         circulating_market_cap = amount['成交额'].iloc[-1] / turnover['换手率'].iloc[-1] * 100\n",
    "#         df.loc[ticker, 'circulating_market_cap'] = circulating_market_cap\n",
    "#     else:\n",
    "#         print(f\"Error: Ticker file for {ticker} does not exist in the folder {baf_path}.\")\n",
    "\n",
    "# # sort the dataframe by the turnover_ratio from highest to lowest\n",
    "# df.sort_values(by='turnover_ratio', ascending=False, inplace=True)\n",
    "\n",
    "# # save the dataframe to a csv file\n",
    "# df.to_csv('turnovers.csv') \n",
    "# df.to_pickle('turnovers.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all stocks 2005换手率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers: 100%|██████████| 5100/5100 [56:45<00:00,  1.50it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2000 saved to turnovers_2000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers: 100%|██████████| 5100/5100 [1:01:54<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2005 saved to turnovers_2005.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers: 100%|██████████| 5100/5100 [1:09:27<00:00,  1.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2010 saved to turnovers_2010.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import akshare as ak\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_stock_data(year):\n",
    "    # Read the JSON data from the file\n",
    "    try:\n",
    "        with open('stock_data/tickers.json') as f:\n",
    "            tickers = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decode error: {e}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    # Prepare start and end dates based on the input year\n",
    "    start_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    # Prepare dataframe\n",
    "    columns = ['tickers', 'turnover_ratio', 'market_cap', 'circulating_market_cap', 'trading_days']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    df.set_index('tickers', inplace=True)\n",
    "\n",
    "    for ticker in tqdm(tickers, desc=\"Processing tickers\"):\n",
    "        try:\n",
    "            # Fetch data from akshare for the given dates\n",
    "            turnover = ak.stock_zh_a_hist(symbol=ticker, start_date=start_date, end_date=end_date, adjust='')[['换手率']]\n",
    "            trading_days = len(turnover)\n",
    "            daily_average_turnover = turnover['换手率'].mean() / 100\n",
    "            df.loc[ticker, 'turnover_ratio'] = daily_average_turnover\n",
    "\n",
    "            amount = ak.stock_zh_a_hist(symbol=ticker, start_date=start_date, end_date=end_date, adjust='')[['成交额']]\n",
    "            circulating_market_cap = amount['成交额'].iloc[-1] / turnover['换手率'].iloc[-1] * 100\n",
    "            df.loc[ticker, 'circulating_market_cap'] = circulating_market_cap\n",
    "\n",
    "            # Add trading days to the dataframe\n",
    "            df.loc[ticker, 'trading_days'] = trading_days\n",
    "\n",
    "        except Exception as e:\n",
    "            df.loc[ticker, ['turnover_ratio', 'circulating_market_cap', 'trading_days']] = [np.nan, np.nan, np.nan]\n",
    "\n",
    "    # Sort and save the dataframe\n",
    "    df.sort_values(by='turnover_ratio', ascending=False, inplace=True)\n",
    "    filename = f'turnovers_{year}.csv'\n",
    "    df.to_csv(filename)\n",
    "    df.to_pickle(f'turnovers_{year}.pkl')\n",
    "    print(f\"Data for {year} saved to {filename}\")\n",
    "\n",
    "years = [2000, 2005, 2010]\n",
    "for year in years:\n",
    "    process_stock_data(year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将csv转为pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 'turnovers_2000.csv' to PKL format.\n",
      "Converted 'turnovers_2005.csv' to PKL format.\n",
      "Converted 'turnovers_2010.csv' to PKL format.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def convert_csv_to_pkl(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_path = os.path.join(folder_path, filename)\n",
    "            pkl_path = os.path.join(folder_path, filename.replace('.csv', '.pkl'))\n",
    "\n",
    "            # 读取CSV文件\n",
    "            df = pd.read_csv(csv_path)\n",
    "\n",
    "            # 将DataFrame保存为PKL文件\n",
    "            df.to_pickle(pkl_path)\n",
    "            print(f\"Converted '{filename}' to PKL format.\")\n",
    "\n",
    "# 定义包含CSV文件的文件夹路径\n",
    "folder_path = '.'\n",
    "\n",
    "# 转换文件夹内的所有CSV文件为PKL\n",
    "convert_csv_to_pkl(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, ifft\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '000001.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "close_data = df['close'].values\n",
    "\n",
    "fft_close = fft(close_data) # 执行FFT\n",
    "n = close_data.size \n",
    "frequency = np.fft.fftfreq(n)   # 获取频率\n",
    "\n",
    "threshold = 0.1 # 设置低通滤波器的阈值\n",
    "low_pass_filter = frequency < threshold\n",
    "\n",
    "filtered_fft_close = fft_close * low_pass_filter    # 应用低通滤波\n",
    "smoothed_close_data = ifft(filtered_fft_close).real # 执行逆FFT来获取平滑后的数据\n",
    "\n",
    "# # 绘制原始和平滑后的'close'数据\n",
    "# plt.figure(figsize=(24, 6))\n",
    "# plt.plot(close_data, label='Original Close Data', alpha=0.7)\n",
    "# plt.plot(smoothed_close_data, label='Smoothed Close Data', color='red')\n",
    "# plt.legend()\n",
    "# plt.title(\"Original vs Smoothed Close Data Using FFT\")\n",
    "# plt.xlabel(\"Data Points\")\n",
    "# plt.ylabel(\"Close Values\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# 将close原始数据和平滑后的数据保存到CSV文件\n",
    "# 在新的csv文件中仅保留日期、原close数据和平滑后的close数据\n",
    "df['smoothed_close'] = smoothed_close_data\n",
    "df = df[['trade_time', 'close', 'smoothed_close']]\n",
    "df.to_csv('smoothed_close.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取历年流动性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2000: 100%|██████████| 5100/5100 [11:44<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2000 saved to stock_data/data/turnover/turnovers_2000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2001: 100%|██████████| 5100/5100 [14:02<00:00,  6.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2001 saved to stock_data/data/turnover/turnovers_2001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2002: 100%|██████████| 5100/5100 [11:40<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2002 saved to stock_data/data/turnover/turnovers_2002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2003:   6%|▌         | 297/5100 [00:54<14:30,  5.51it/s]/var/folders/hq/_g19nv1x12q8zgzl5rqyk53w0000gn/T/ipykernel_73676/1241144395.py:24: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  circulating_market_cap = amount['成交额'].iloc[-1] / turnover['换手率'].iloc[-1] * 100\n",
      "Processing 2003: 100%|██████████| 5100/5100 [09:18<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2003 saved to stock_data/data/turnover/turnovers_2003.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2004:   6%|▌         | 298/5100 [00:58<14:53,  5.38it/s]/var/folders/hq/_g19nv1x12q8zgzl5rqyk53w0000gn/T/ipykernel_73676/1241144395.py:24: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  circulating_market_cap = amount['成交额'].iloc[-1] / turnover['换手率'].iloc[-1] * 100\n",
      "Processing 2004: 100%|██████████| 5100/5100 [11:16<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2004 saved to stock_data/data/turnover/turnovers_2004.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2005: 100%|██████████| 5100/5100 [13:26<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2005 saved to stock_data/data/turnover/turnovers_2005.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2006: 100%|██████████| 5100/5100 [13:17<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2006 saved to stock_data/data/turnover/turnovers_2006.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2007:   5%|▌         | 255/5100 [01:14<26:54,  3.00it/s]/var/folders/hq/_g19nv1x12q8zgzl5rqyk53w0000gn/T/ipykernel_73676/1241144395.py:24: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  circulating_market_cap = amount['成交额'].iloc[-1] / turnover['换手率'].iloc[-1] * 100\n",
      "Processing 2007: 100%|██████████| 5100/5100 [12:35<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2007 saved to stock_data/data/turnover/turnovers_2007.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2008:   6%|▌         | 286/5100 [01:13<22:13,  3.61it/s]/var/folders/hq/_g19nv1x12q8zgzl5rqyk53w0000gn/T/ipykernel_73676/1241144395.py:24: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  circulating_market_cap = amount['成交额'].iloc[-1] / turnover['换手率'].iloc[-1] * 100\n",
      "Processing 2008: 100%|██████████| 5100/5100 [12:45<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2008 saved to stock_data/data/turnover/turnovers_2008.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2009: 100%|██████████| 5100/5100 [13:32<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2009 saved to stock_data/data/turnover/turnovers_2009.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2010: 100%|██████████| 5100/5100 [14:09<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2010 saved to stock_data/data/turnover/turnovers_2010.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2011: 100%|██████████| 5100/5100 [12:01<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2011 saved to stock_data/data/turnover/turnovers_2011.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2012: 100%|██████████| 5100/5100 [14:32<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2012 saved to stock_data/data/turnover/turnovers_2012.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2013: 100%|██████████| 5100/5100 [16:33<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2013 saved to stock_data/data/turnover/turnovers_2013.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2014: 100%|██████████| 5100/5100 [20:20<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2014 saved to stock_data/data/turnover/turnovers_2014.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2015: 100%|██████████| 5100/5100 [17:47<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2015 saved to stock_data/data/turnover/turnovers_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2016: 100%|██████████| 5100/5100 [19:14<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2016 saved to stock_data/data/turnover/turnovers_2016.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2017:  60%|██████    | 3063/5100 [10:20<08:03,  4.21it/s]/var/folders/hq/_g19nv1x12q8zgzl5rqyk53w0000gn/T/ipykernel_73676/1241144395.py:24: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  circulating_market_cap = amount['成交额'].iloc[-1] / turnover['换手率'].iloc[-1] * 100\n",
      "Processing 2017: 100%|██████████| 5100/5100 [15:07<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2017 saved to stock_data/data/turnover/turnovers_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2018: 100%|██████████| 5100/5100 [13:38<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2018 saved to stock_data/data/turnover/turnovers_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2019: 100%|██████████| 5100/5100 [19:06<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2019 saved to stock_data/data/turnover/turnovers_2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2020: 100%|██████████| 5100/5100 [12:09<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2020 saved to stock_data/data/turnover/turnovers_2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2021: 100%|██████████| 5100/5100 [12:39<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2021 saved to stock_data/data/turnover/turnovers_2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2022: 100%|██████████| 5100/5100 [16:48<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2022 saved to stock_data/data/turnover/turnovers_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2023:  60%|██████    | 3077/5100 [10:33<06:15,  5.39it/s]/var/folders/hq/_g19nv1x12q8zgzl5rqyk53w0000gn/T/ipykernel_73676/1241144395.py:24: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  circulating_market_cap = amount['成交额'].iloc[-1] / turnover['换手率'].iloc[-1] * 100\n",
      "Processing 2023: 100%|██████████| 5100/5100 [17:39<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2023 saved to stock_data/data/turnover/turnovers_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import akshare as ak\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_stock_data(year, ticker):\n",
    "    # Prepare start and end dates\n",
    "    start_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    try:\n",
    "        # Fetch data from akshare\n",
    "        turnover = ak.stock_zh_a_hist(symbol=ticker, start_date=start_date, end_date=end_date, adjust='')[['换手率']]\n",
    "        amount = ak.stock_zh_a_hist(symbol=ticker, start_date=start_date, end_date=end_date, adjust='')[['成交额']]\n",
    "\n",
    "        if turnover.empty or amount.empty:\n",
    "            return None\n",
    "\n",
    "        trading_days = len(turnover)\n",
    "        daily_average_turnover = turnover['换手率'].mean() / 100\n",
    "\n",
    "        # 筛选出所有非零换手率的记录\n",
    "        non_zero_turnover = turnover[turnover['换手率'] != 0]\n",
    "        if not non_zero_turnover.empty:\n",
    "            last_valid_index = non_zero_turnover.index[-1]\n",
    "            last_valid_turnover = turnover.loc[last_valid_index, '换手率']\n",
    "            corresponding_amount = amount.loc[last_valid_index, '成交额']\n",
    "            circulating_market_cap = corresponding_amount / last_valid_turnover * 100\n",
    "        else:\n",
    "            # 如果没有非零换手率，设置为NaN或其他合适的值\n",
    "            circulating_market_cap = np.nan\n",
    "\n",
    "        return [ticker, daily_average_turnover, circulating_market_cap, trading_days]\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        with open('stock_data/tickers.json') as f:\n",
    "            tickers = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading tickers file: {e}\")\n",
    "        return\n",
    "\n",
    "    years = range(2000, 2024)\n",
    "    max_workers = max(1, os.cpu_count() - 1)  # 保留一个CPU核心\n",
    "\n",
    "    turnover_dir = 'stock_data/data/turnover'\n",
    "    if not os.path.exists(turnover_dir):\n",
    "        os.makedirs(turnover_dir)\n",
    "\n",
    "    for year in years:\n",
    "        results = []\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # 在这里为每个ticker创建一个进度条\n",
    "            futures = {executor.submit(process_stock_data, year, ticker): ticker for ticker in tickers}\n",
    "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(tickers), desc=f\"Processing {year}\"):\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    results.append(result)\n",
    "\n",
    "        if results:\n",
    "            df = pd.DataFrame(results, columns=['tickers', 'turnover_ratio', 'circulating_market_cap', 'trading_days'])\n",
    "            df.set_index('tickers', inplace=True)\n",
    "            df.sort_values(by='turnover_ratio', ascending=False, inplace=True)\n",
    "            filename = os.path.join(turnover_dir, f'turnovers_{year}.csv')\n",
    "            df.to_csv(filename)\n",
    "            df.to_pickle(os.path.join(turnover_dir, f'turnovers_{year}.pkl'))\n",
    "            print(f\"Data for {year} saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
