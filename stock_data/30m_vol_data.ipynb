{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算每个股票的30min总成交额"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1427/5100 [1:58:24<7:40:53,  7.53s/it] "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor,as_completed\n",
    "\n",
    "def process_stock_data(file_name, input_folder, output_folder):\n",
    "    # 检查输出文件是否已存在\n",
    "    output_file_path = os.path.join(output_folder, file_name)\n",
    "    if os.path.exists(output_file_path):\n",
    "        return\n",
    "    \n",
    "    # 读取数据\n",
    "    df = pd.read_csv(os.path.join(input_folder, file_name))\n",
    "    \n",
    "    # 按30行分组并处理数据\n",
    "    result = []\n",
    "    for i in range(0, len(df), 30):\n",
    "        batch = df.iloc[i:i+30]\n",
    "        if not batch.empty:\n",
    "            total_amount = batch['amount'].sum()\n",
    "            timestamp = batch.iloc[-1]['trade_time']\n",
    "            result.append([timestamp, total_amount])\n",
    "    \n",
    "    # 保存到新的DataFrame中\n",
    "    processed_df = pd.DataFrame(result, columns=['trade_time', 'total_amount'])\n",
    "    \n",
    "    # 写入到新文件中\n",
    "    processed_df.to_csv(os.path.join(output_folder, file_name), index=False)\n",
    "\n",
    "def main(input_folder, output_folder):\n",
    "    files = os.listdir(input_folder)\n",
    "\n",
    "    # 确保输出文件夹存在\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 使用线程池执行任务\n",
    "    with ThreadPoolExecutor(max_workers=os.cpu_count() - 5) as executor:\n",
    "        futures = [executor.submit(process_stock_data, file, input_folder, output_folder) for file in files]\n",
    "        \n",
    "        # 使用tqdm显示进度条\n",
    "        for future in tqdm(as_completed(futures), total=len(files)):\n",
    "            future.result()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = 'data/by_stock_merged'  # 修改为您的输入文件夹路径\n",
    "    output_folder = 'data/v30/by_stock_v30'  # 修改为您的输出文件夹路径\n",
    "    main(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算交易额强度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5100/5100 [10:01<00:00,  8.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_file(file_path):\n",
    "    # 读取文件\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # 提取日期和时间\n",
    "    df['date'] = pd.to_datetime(df['trade_time']).dt.date\n",
    "    df['time'] = pd.to_datetime(df['trade_time']).dt.time\n",
    "\n",
    "    # 计算10天平均值（不包括当天）\n",
    "    df['v_avg30'] = df.groupby('time')['total_amount'].apply(\n",
    "        lambda x: x.shift().rolling(window=10, min_periods=1).mean()).reset_index(level=0, drop=True)\n",
    "\n",
    "    # 第一个交易日的数据置0\n",
    "    first_day = df['date'].min()\n",
    "    df.loc[df['date'] == first_day, 'v_avg30'] = 0\n",
    "\n",
    "    # 添加v_str30列\n",
    "    df['v_str30'] = df['total_amount'] / df['v_avg30']\n",
    "    df.loc[df['date'] == first_day, 'v_str30'] = 0\n",
    "\n",
    "    # 删除辅助列\n",
    "    df.drop(columns=['date', 'time'], inplace=True)\n",
    "\n",
    "    # 保存结果\n",
    "    output_file_path = os.path.join(output_folder, os.path.basename(file_path))\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "def process_files_in_folder(folder_path, output_folder):\n",
    "    files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    # 使用CPU核心数-1的线程\n",
    "    num_threads = max(1, os.cpu_count() - 1)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        list(tqdm(executor.map(process_file, files), total=len(files)))\n",
    "\n",
    "# 要处理的文件夹路径\n",
    "folder_path = 'data/v30/by_stock_v30' # 替换为您的数据文件夹路径\n",
    "output_folder = 'data/v30/by_stock_v_str30' # 替换为您的输出文件夹路径\n",
    "\n",
    "# 确保输出文件夹存在\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# 处理文件夹中的文件\n",
    "process_files_in_folder(folder_path, output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5100/5100 [23:45<00:00,  3.58it/s]\n",
      " 97%|█████████▋| 4933/5100 [22:29<01:19,  2.09it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm  # 导入tqdm\n",
    "\n",
    "def merge_column(folder, column_name, output_file):\n",
    "    merged_df = None\n",
    "\n",
    "    files = os.listdir(folder)  # 获取文件列表\n",
    "    for file in tqdm(files):  # 使用tqdm包裹文件列表以显示进度\n",
    "        file_path = os.path.join(folder, file)\n",
    "        if file.endswith('.csv'):\n",
    "            ticker = os.path.splitext(file)[0]\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # 只保留 trade_time 和特定的列\n",
    "            df = df[['trade_time', column_name]]\n",
    "            df.rename(columns={column_name: ticker}, inplace=True)\n",
    "\n",
    "            if merged_df is None:\n",
    "                merged_df = df\n",
    "            else:\n",
    "                merged_df = pd.merge_ordered(merged_df, df, on='trade_time')\n",
    "\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "output_folder = 'data/v30/by_stock_v_str30'  # 已处理数据的输出文件夹路径\n",
    "\n",
    "# 分别为 total_amount, v_avg30 和 v_str30 合并数据\n",
    "merge_column(output_folder, 'total_amount', 'data/v30/merged_amount.csv')\n",
    "merge_column(output_folder, 'v_avg30', 'data/v30/merged_avg.csv')\n",
    "merge_column(output_folder, 'v_str30', 'data/v30/merged_str.csv')\n",
    "\n",
    "print(\"所有数据合并完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "folder_path = 'data/v30'\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        pkl_file_path = os.path.join(folder_path, os.path.splitext(file)[0] + '.pkl')\n",
    "        df.to_pickle(\n",
    "            pkl_file_path, \n",
    "            #compression='zip'\n",
    "            )\n",
    "\n",
    "print(\"所有文件已转换完成。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
