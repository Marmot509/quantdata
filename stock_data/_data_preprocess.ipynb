{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 从2024年股票数据中获取所有股票的代码\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define the updated function to modify the filenames as required\n",
    "def get_ticker_with_prefix(path):\n",
    "    tickers = []\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.csv'):\n",
    "            # Extract numeric part\n",
    "            numeric_part = ''.join(filter(str.isdigit, f))\n",
    "            # Extract the letter part (.SZ or .SH), convert to lowercase and prepend to the numeric part\n",
    "            letter_part = f.split('.')[1].lower()\n",
    "            ticker = letter_part + numeric_part\n",
    "            tickers.append(ticker)\n",
    "    # Sort the list of IDs\n",
    "    return sorted(tickers)\n",
    "\n",
    "# Replace 'path_to_folder' with the actual path to your folder containing the CSV files\n",
    "path_to_folder = 'data/2024'\n",
    "\n",
    "# Get the modified stock ids\n",
    "tickers_with_prefix = get_ticker_with_prefix(path_to_folder)\n",
    "\n",
    "# Convert the list of modified stock ids to JSON format\n",
    "json_content = json.dumps(tickers_with_prefix, indent=4)\n",
    "\n",
    "# Replace 'path_to_json_file' with the actual path where you want to save the JSON file\n",
    "path_to_json_file = 'data/ticker.json'\n",
    "\n",
    "# Write the JSON content to a file\n",
    "with open(path_to_json_file, 'w') as json_file:\n",
    "    json_file.write(json_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 从 akshare 获取后复权因子数据，并保存在 CSV 文件中\n",
    "\n",
    "import akshare as ak\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 读取股票代码\n",
    "path_to_json_file = 'data/ticker.json'\n",
    "with open(path_to_json_file, 'r') as json_file:\n",
    "    tickers = json.load(json_file)\n",
    "\n",
    "# 检查并获取后复权因子\n",
    "for ticker in tickers:\n",
    "    filename = f\"{ticker}.csv\"\n",
    "\n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(\"data/backward_adjust_factor/\" + filename):\n",
    "        try:\n",
    "            # 尝试调用 API 获取数据\n",
    "            df = ak.stock_zh_a_daily(symbol=ticker, adjust=\"hfq-factor\")\n",
    "            # 保存数据到 CSV 文件\n",
    "            df.to_csv(\"data/backward_adjust_factor/\" + filename, index=False)\n",
    "            print(f\"{ticker} data saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            # 打印错误信息，并继续处理下一个 ticker\n",
    "            print(f\"Error retrieving data for {ticker}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {filename} already exists. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 处理股票tickers，去掉数字后面的.和字母\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 假设你的json文件名为'top_market_cap_stocks.json'\n",
    "with open('data/top_market_cap_stocks.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 遍历json文件中的所有字符串\n",
    "for i in range(len(data)):\n",
    "    # 使用正则表达式去掉数字后面的.和字母\n",
    "    data[i] = re.sub(r'(\\d)\\.[a-zA-Z]*', r'\\1', data[i])\n",
    "\n",
    "data = sorted(data)\n",
    "\n",
    "# 将修改后的数据写回json文件\n",
    "with open('data/top_market_cap_stocks.json', 'w') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 使用价格数据后复权后计算股票收益率\n",
    "# ### 已弃用\n",
    "\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # 假设股票价格数据的文件路径\n",
    "# stock_prices_path = 'data/merged_data.csv'\n",
    "# # 假设后复权因子文件夹的路径\n",
    "# adjust_factor_path = 'data/backward_adjust_factor/'\n",
    "\n",
    "# # 分块大小\n",
    "# chunksize = 10**5  \n",
    "\n",
    "# # 读取股票价格数据的行数来计算总块数\n",
    "# total_rows = sum(1 for row in open(stock_prices_path, 'r'))\n",
    "# total_chunks = total_rows // chunksize + (total_rows % chunksize > 0)\n",
    "\n",
    "# # 初始化存储后复权价格的DataFrame\n",
    "# adjusted_prices = None\n",
    "\n",
    "# # 使用tqdm显示进度条\n",
    "# with tqdm(total=total_chunks, desc=\"Processing chunks\") as pbar:\n",
    "#     for chunk in pd.read_csv(stock_prices_path, chunksize=chunksize):\n",
    "#         chunk['trade_time'] = pd.to_datetime(chunk['trade_time'])\n",
    "#         if adjusted_prices is None:\n",
    "#             adjusted_prices = pd.DataFrame()\n",
    "#             adjusted_prices['trade_time'] = chunk['trade_time']\n",
    "\n",
    "#         # 对于每个股票代码\n",
    "#         for stock_code in chunk.columns[1:]:\n",
    "#             try:\n",
    "#                 # 尝试加载后复权因子文件\n",
    "#                 hfq_factor_file = f'{adjust_factor_path}sh{stock_code}.csv'\n",
    "#                 hfq_factors = pd.read_csv(hfq_factor_file)\n",
    "#             except FileNotFoundError:\n",
    "#                 try:\n",
    "#                     hfq_factor_file = f'{adjust_factor_path}sz{stock_code}.csv'\n",
    "#                     hfq_factors = pd.read_csv(hfq_factor_file)\n",
    "#                 except FileNotFoundError:\n",
    "#                     # 如果都找不到，打印信息并跳过该股票\n",
    "#                     print(f\"未找到股票 {stock_code} 的后复权因子文件\")\n",
    "#                     continue\n",
    "\n",
    "#             hfq_factors['date'] = pd.to_datetime(hfq_factors['date'])\n",
    "#             hfq_factors.sort_values('date', inplace=True)\n",
    "#             hfq_factors.set_index('date', inplace=True)\n",
    "\n",
    "#             # 计算后复权价格\n",
    "#             adjusted_chunk = chunk.apply(\n",
    "#                 lambda row: row[stock_code] * hfq_factors.loc[:row['trade_time']].iloc[-1]['hfq_factor'],\n",
    "#                 axis=1\n",
    "#             )\n",
    "#             adjusted_prices[stock_code] = adjusted_chunk\n",
    "\n",
    "#         pbar.update(1)  # 更新进度条\n",
    "\n",
    "# # 设置交易时间为索引\n",
    "# adjusted_prices.set_index('trade_time', inplace=True)\n",
    "\n",
    "# # 保存结果\n",
    "# adjusted_prices.to_csv('data/stock_prices_hfq.csv', index=True)\n",
    "# print('data/stock_prices_hfq.csv saved')\n",
    "\n",
    "# # 计算收益率\n",
    "# returns = adjusted_prices.pct_change()\n",
    "# print('returns calculated')\n",
    "\n",
    "# # 移除收益率DataFrame中的第一行，因为它将会是NaN（第一个点没有前一个点来计算收益率）\n",
    "# returns = returns.iloc[1:]\n",
    "\n",
    "# # 将收益率DataFrame保存为CSV文件\n",
    "# returns.to_csv('data/stock_returns.csv', index=True)\n",
    "# print('data/stock_returns.csv saved')\n",
    "\n",
    "# # 将收益率DataFrame保存为序列化的二进制文件（Pickle格式）\n",
    "# returns.to_pickle('data/stock_returns.pkl')\n",
    "# print('data/stock_returns.pkl saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 处理收益率\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# 设定路径\n",
    "#path_to_stock_returns = 'data/stock_returns_test.csv'\n",
    "path_to_stock_returns = 'data/stock_returns.csv'\n",
    "\n",
    "path_to_hfq_data_folder = 'data/backward_adjust_factor/'\n",
    "\n",
    "\n",
    "\n",
    "# 读取股票回报率数据\n",
    "stock_returns = pd.read_csv(path_to_stock_returns)\n",
    "stock_returns['trade_time'] = pd.to_datetime(stock_returns['trade_time'])\n",
    "stock_returns.set_index('trade_time', inplace=True)\n",
    "\n",
    "# 遍历 stock_returns 的列\n",
    "for ticker in stock_returns.columns:  # 包括所有列\n",
    "    file_found = False\n",
    "    # 尝试找到hfq_data_path中sh+ticker.csv或者sz+ticker.csv文件\n",
    "    for prefix in ['sh', 'sz']:\n",
    "        filename = f'{prefix}{ticker}.csv'\n",
    "        file_path = os.path.join(path_to_hfq_data_folder, filename)\n",
    "        if os.path.exists(file_path):\n",
    "            hfq_data = pd.read_csv(file_path)\n",
    "            hfq_data['date'] = pd.to_datetime(hfq_data['date'])\n",
    "            file_found = True\n",
    "            break\n",
    "\n",
    "    if file_found:\n",
    "        # 遍历hfq_data中日期在2000年1月1日以后的数据\n",
    "        for index, row in hfq_data[hfq_data['date'] > '2000-01-01'].iterrows():\n",
    "            # 在日期后增加09:31:00的时间\n",
    "            trade_time = row['date'] + datetime.timedelta(hours=9, minutes=31)\n",
    "            # 处理对应的收益率数据\n",
    "            if trade_time in stock_returns.index:\n",
    "                stock_returns.at[trade_time, ticker] = (stock_returns.at[trade_time, ticker] + 1) * row['hfq_one_point'] - 1\n",
    "    else:\n",
    "        print(f'No hfq_one_point data file found for ticker {ticker}. Skipping...')\n",
    "\n",
    "# 保存处理后的数据\n",
    "#stock_returns.to_csv('data/adjusted_return_test.csv')\n",
    "stock_returns.to_csv('data/adjusted_return.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers:  13%|█▎        | 90/696 [00:02<00:11, 51.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hfq_one_point data file found for ticker 001696. Skipping...\n",
      "No hfq_one_point data file found for ticker 001872. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers:  24%|██▎       | 164/696 [00:03<00:12, 43.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hfq_one_point data file found for ticker 001914. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers: 100%|██████████| 696/696 [00:05<00:00, 117.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hfq_one_point data file found for ticker 001896. Skipping...\n"
     ]
    }
   ],
   "source": [
    "### 处理收益率\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm  # 引入tqdm库\n",
    "\n",
    "# 设定路径\n",
    "path_to_stock_returns = 'data/stock_returns.csv'\n",
    "path_to_hfq_data_folder = 'data/backward_adjust_factor/'\n",
    "\n",
    "# 读取股票回报率数据\n",
    "stock_returns = pd.read_csv(path_to_stock_returns)\n",
    "stock_returns['trade_time'] = pd.to_datetime(stock_returns['trade_time'])\n",
    "stock_returns.set_index('trade_time', inplace=True)\n",
    "\n",
    "# 使用tqdm创建进度条\n",
    "for ticker in tqdm(stock_returns.columns, desc=\"Processing tickers\"):  # 包括所有列，并添加进度条\n",
    "    file_found = False\n",
    "    # 尝试找到hfq_data_path中sh+ticker.csv或者sz+ticker.csv文件\n",
    "    for prefix in ['sh', 'sz']:\n",
    "        filename = f'{prefix}{ticker}.csv'\n",
    "        file_path = os.path.join(path_to_hfq_data_folder, filename)\n",
    "        if os.path.exists(file_path):\n",
    "            hfq_data = pd.read_csv(file_path)\n",
    "            hfq_data['date'] = pd.to_datetime(hfq_data['date'])\n",
    "            file_found = True\n",
    "            break\n",
    "\n",
    "    if file_found:\n",
    "        # 遍历hfq_data中日期在2000年1月1日以后的数据\n",
    "        for index, row in hfq_data[hfq_data['date'] > '2000-01-01'].iterrows():\n",
    "            # 在日期后增加09:31:00的时间\n",
    "            trade_time = row['date'] + datetime.timedelta(hours=9, minutes=31)\n",
    "            # 处理对应的收益率数据\n",
    "            if trade_time in stock_returns.index:\n",
    "                stock_returns.at[trade_time, ticker] = (stock_returns.at[trade_time, ticker] + 1) * row['hfq_one_point'] - 1\n",
    "    else:\n",
    "        print(f'No hfq_one_point data file found for ticker {ticker}. Skipping...')\n",
    "\n",
    "# 保存处理后的数据\n",
    "stock_returns.to_csv('data/adjusted_return.csv')\n",
    "stock_returns.to_pickle('data/stock_returns.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
