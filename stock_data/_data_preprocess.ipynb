{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 从2024年股票数据中获取所有股票的代码\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define the updated function to modify the filenames as required\n",
    "def get_ticker_with_prefix(path):\n",
    "    tickers = []\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.csv'):\n",
    "            # Extract numeric part\n",
    "            numeric_part = ''.join(filter(str.isdigit, f))\n",
    "            # Extract the letter part (.SZ or .SH), convert to lowercase and prepend to the numeric part\n",
    "            letter_part = f.split('.')[1].lower()\n",
    "            ticker = letter_part + numeric_part\n",
    "            tickers.append(ticker)\n",
    "    # Sort the list of IDs\n",
    "    return sorted(tickers)\n",
    "\n",
    "# Replace 'path_to_folder' with the actual path to your folder containing the CSV files\n",
    "path_to_folder = 'data/2024'\n",
    "\n",
    "# Get the modified stock ids\n",
    "tickers_with_prefix = get_ticker_with_prefix(path_to_folder)\n",
    "\n",
    "# Convert the list of modified stock ids to JSON format\n",
    "json_content = json.dumps(tickers_with_prefix, indent=4)\n",
    "\n",
    "# Replace 'path_to_json_file' with the actual path where you want to save the JSON file\n",
    "path_to_json_file = 'data/ticker.json'\n",
    "\n",
    "# Write the JSON content to a file\n",
    "with open(path_to_json_file, 'w') as json_file:\n",
    "    json_file.write(json_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 从 akshare 获取后复权因子数据，并保存在 CSV 文件中\n",
    "\n",
    "import akshare as ak\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 读取股票代码\n",
    "path_to_json_file = 'data/ticker.json'\n",
    "with open(path_to_json_file, 'r') as json_file:\n",
    "    tickers = json.load(json_file)\n",
    "\n",
    "# 检查并获取后复权因子\n",
    "for ticker in tickers:\n",
    "    filename = f\"{ticker}.csv\"\n",
    "\n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(\"data/backward_adjust_factor/\" + filename):\n",
    "        try:\n",
    "            # 尝试调用 API 获取数据\n",
    "            df = ak.stock_zh_a_daily(symbol=ticker, adjust=\"hfq-factor\")\n",
    "            # 保存数据到 CSV 文件\n",
    "            df.to_csv(\"data/backward_adjust_factor/\" + filename, index=False)\n",
    "            print(f\"{ticker} data saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            # 打印错误信息，并继续处理下一个 ticker\n",
    "            print(f\"Error retrieving data for {ticker}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {filename} already exists. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 处理股票tickers，去掉数字后面的.和字母\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 假设你的json文件名为'top_market_cap_stocks.json'\n",
    "with open('data/top_market_cap_stocks.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 遍历json文件中的所有字符串\n",
    "for i in range(len(data)):\n",
    "    # 使用正则表达式去掉数字后面的.和字母\n",
    "    data[i] = re.sub(r'(\\d)\\.[a-zA-Z]*', r'\\1', data[i])\n",
    "\n",
    "data = sorted(data)\n",
    "\n",
    "# 将修改后的数据写回json文件\n",
    "with open('data/top_market_cap_stocks.json', 'w') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 使用价格数据后复权后计算股票收益率\n",
    "### 已弃用\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 假设股票价格数据的文件路径\n",
    "stock_prices_path = 'data/merged_data.csv'\n",
    "# 假设后复权因子文件夹的路径\n",
    "adjust_factor_path = 'data/backward_adjust_factor/'\n",
    "\n",
    "# 分块大小\n",
    "chunksize = 10**5  \n",
    "\n",
    "# 读取股票价格数据的行数来计算总块数\n",
    "total_rows = sum(1 for row in open(stock_prices_path, 'r'))\n",
    "total_chunks = total_rows // chunksize + (total_rows % chunksize > 0)\n",
    "\n",
    "# 初始化存储后复权价格的DataFrame\n",
    "adjusted_prices = None\n",
    "\n",
    "# 使用tqdm显示进度条\n",
    "with tqdm(total=total_chunks, desc=\"Processing chunks\") as pbar:\n",
    "    for chunk in pd.read_csv(stock_prices_path, chunksize=chunksize):\n",
    "        chunk['trade_time'] = pd.to_datetime(chunk['trade_time'])\n",
    "        if adjusted_prices is None:\n",
    "            adjusted_prices = pd.DataFrame()\n",
    "            adjusted_prices['trade_time'] = chunk['trade_time']\n",
    "\n",
    "        # 对于每个股票代码\n",
    "        for stock_code in chunk.columns[1:]:\n",
    "            try:\n",
    "                # 尝试加载后复权因子文件\n",
    "                hfq_factor_file = f'{adjust_factor_path}sh{stock_code}.csv'\n",
    "                hfq_factors = pd.read_csv(hfq_factor_file)\n",
    "            except FileNotFoundError:\n",
    "                try:\n",
    "                    hfq_factor_file = f'{adjust_factor_path}sz{stock_code}.csv'\n",
    "                    hfq_factors = pd.read_csv(hfq_factor_file)\n",
    "                except FileNotFoundError:\n",
    "                    # 如果都找不到，打印信息并跳过该股票\n",
    "                    print(f\"未找到股票 {stock_code} 的后复权因子文件\")\n",
    "                    continue\n",
    "\n",
    "            hfq_factors['date'] = pd.to_datetime(hfq_factors['date'])\n",
    "            hfq_factors.sort_values('date', inplace=True)\n",
    "            hfq_factors.set_index('date', inplace=True)\n",
    "\n",
    "            # 计算后复权价格\n",
    "            adjusted_chunk = chunk.apply(\n",
    "                lambda row: row[stock_code] * hfq_factors.loc[:row['trade_time']].iloc[-1]['hfq_factor'],\n",
    "                axis=1\n",
    "            )\n",
    "            adjusted_prices[stock_code] = adjusted_chunk\n",
    "\n",
    "        pbar.update(1)  # 更新进度条\n",
    "\n",
    "# 设置交易时间为索引\n",
    "adjusted_prices.set_index('trade_time', inplace=True)\n",
    "\n",
    "# 保存结果\n",
    "adjusted_prices.to_csv('data/stock_prices_hfq.csv', index=True)\n",
    "print('data/stock_prices_hfq.csv saved')\n",
    "\n",
    "# 计算收益率\n",
    "returns = adjusted_prices.pct_change()\n",
    "print('returns calculated')\n",
    "\n",
    "# 移除收益率DataFrame中的第一行，因为它将会是NaN（第一个点没有前一个点来计算收益率）\n",
    "returns = returns.iloc[1:]\n",
    "\n",
    "# 将收益率DataFrame保存为CSV文件\n",
    "returns.to_csv('data/stock_returns.csv', index=True)\n",
    "print('data/stock_returns.csv saved')\n",
    "\n",
    "# 将收益率DataFrame保存为序列化的二进制文件（Pickle格式）\n",
    "returns.to_pickle('data/stock_returns.pkl')\n",
    "print('data/stock_returns.pkl saved')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
