{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 从2024年股票数据中获取所有股票的代码\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define the updated function to modify the filenames as required\n",
    "def get_ticker_with_prefix(path):\n",
    "    tickers = []\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.csv'):\n",
    "            # Extract numeric part\n",
    "            numeric_part = ''.join(filter(str.isdigit, f))\n",
    "            # Extract the letter part (.SZ or .SH), convert to lowercase and prepend to the numeric part\n",
    "            letter_part = f.split('.')[1].lower()\n",
    "            ticker = letter_part + numeric_part\n",
    "            tickers.append(ticker)\n",
    "    # Sort the list of IDs\n",
    "    return sorted(tickers)\n",
    "\n",
    "# Replace 'path_to_folder' with the actual path to your folder containing the CSV files\n",
    "path_to_folder = 'data/2024'\n",
    "\n",
    "# Get the modified stock ids\n",
    "tickers_with_prefix = get_ticker_with_prefix(path_to_folder)\n",
    "\n",
    "# Convert the list of modified stock ids to JSON format\n",
    "json_content = json.dumps(tickers_with_prefix, indent=4)\n",
    "\n",
    "# Replace 'path_to_json_file' with the actual path where you want to save the JSON file\n",
    "path_to_json_file = 'data/ticker.json'\n",
    "\n",
    "# Write the JSON content to a file\n",
    "with open(path_to_json_file, 'w') as json_file:\n",
    "    json_file.write(json_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'akshare'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### 从 akshare 获取后复权因子数据，并保存在 CSV 文件中\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01makshare\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mak\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'akshare'"
     ]
    }
   ],
   "source": [
    "### 从 akshare 获取后复权因子数据，并保存在 CSV 文件中\n",
    "\n",
    "import akshare as ak\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 读取股票代码\n",
    "path_to_json_file = 'data/ticker.json'\n",
    "with open(path_to_json_file, 'r') as json_file:\n",
    "    tickers = json.load(json_file)\n",
    "\n",
    "# 检查并获取后复权因子\n",
    "for ticker in tickers:\n",
    "    filename = f\"{ticker}.csv\"\n",
    "\n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(\"data/backward_adjust_factor/\" + filename):\n",
    "        try:\n",
    "            # 尝试调用 API 获取数据\n",
    "            df = ak.stock_zh_a_daily(symbol=ticker, adjust=\"hfq-factor\")\n",
    "            # 保存数据到 CSV 文件\n",
    "            df.to_csv(\"data/backward_adjust_factor/\" + filename, index=False)\n",
    "            print(f\"{ticker} data saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            # 打印错误信息，并继续处理下一个 ticker\n",
    "            print(f\"Error retrieving data for {ticker}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {filename} already exists. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 处理股票tickers，去掉数字后面的.和字母\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 假设你的json文件名为'top_market_cap_stocks.json'\n",
    "with open('data/top_market_cap_stocks.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 遍历json文件中的所有字符串\n",
    "for i in range(len(data)):\n",
    "    # 使用正则表达式去掉数字后面的.和字母\n",
    "    data[i] = re.sub(r'(\\d)\\.[a-zA-Z]*', r'\\1', data[i])\n",
    "\n",
    "data = sorted(data)\n",
    "\n",
    "# 将修改后的数据写回json文件\n",
    "with open('data/top_market_cap_stocks.json', 'w') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 使用价格数据后复权后计算股票收益率\n",
    "# ### 已弃用\n",
    "\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # 假设股票价格数据的文件路径\n",
    "# stock_prices_path = 'data/merged_data.csv'\n",
    "# # 假设后复权因子文件夹的路径\n",
    "# adjust_factor_path = 'data/backward_adjust_factor/'\n",
    "\n",
    "# # 分块大小\n",
    "# chunksize = 10**5  \n",
    "\n",
    "# # 读取股票价格数据的行数来计算总块数\n",
    "# total_rows = sum(1 for row in open(stock_prices_path, 'r'))\n",
    "# total_chunks = total_rows // chunksize + (total_rows % chunksize > 0)\n",
    "\n",
    "# # 初始化存储后复权价格的DataFrame\n",
    "# adjusted_prices = None\n",
    "\n",
    "# # 使用tqdm显示进度条\n",
    "# with tqdm(total=total_chunks, desc=\"Processing chunks\") as pbar:\n",
    "#     for chunk in pd.read_csv(stock_prices_path, chunksize=chunksize):\n",
    "#         chunk['trade_time'] = pd.to_datetime(chunk['trade_time'])\n",
    "#         if adjusted_prices is None:\n",
    "#             adjusted_prices = pd.DataFrame()\n",
    "#             adjusted_prices['trade_time'] = chunk['trade_time']\n",
    "\n",
    "#         # 对于每个股票代码\n",
    "#         for stock_code in chunk.columns[1:]:\n",
    "#             try:\n",
    "#                 # 尝试加载后复权因子文件\n",
    "#                 hfq_factor_file = f'{adjust_factor_path}sh{stock_code}.csv'\n",
    "#                 hfq_factors = pd.read_csv(hfq_factor_file)\n",
    "#             except FileNotFoundError:\n",
    "#                 try:\n",
    "#                     hfq_factor_file = f'{adjust_factor_path}sz{stock_code}.csv'\n",
    "#                     hfq_factors = pd.read_csv(hfq_factor_file)\n",
    "#                 except FileNotFoundError:\n",
    "#                     # 如果都找不到，打印信息并跳过该股票\n",
    "#                     print(f\"未找到股票 {stock_code} 的后复权因子文件\")\n",
    "#                     continue\n",
    "\n",
    "#             hfq_factors['date'] = pd.to_datetime(hfq_factors['date'])\n",
    "#             hfq_factors.sort_values('date', inplace=True)\n",
    "#             hfq_factors.set_index('date', inplace=True)\n",
    "\n",
    "#             # 计算后复权价格\n",
    "#             adjusted_chunk = chunk.apply(\n",
    "#                 lambda row: row[stock_code] * hfq_factors.loc[:row['trade_time']].iloc[-1]['hfq_factor'],\n",
    "#                 axis=1\n",
    "#             )\n",
    "#             adjusted_prices[stock_code] = adjusted_chunk\n",
    "\n",
    "#         pbar.update(1)  # 更新进度条\n",
    "\n",
    "# # 设置交易时间为索引\n",
    "# adjusted_prices.set_index('trade_time', inplace=True)\n",
    "\n",
    "# # 保存结果\n",
    "# adjusted_prices.to_csv('data/stock_prices_hfq.csv', index=True)\n",
    "# print('data/stock_prices_hfq.csv saved')\n",
    "\n",
    "# # 计算收益率\n",
    "# returns = adjusted_prices.pct_change()\n",
    "# print('returns calculated')\n",
    "\n",
    "# # 移除收益率DataFrame中的第一行，因为它将会是NaN（第一个点没有前一个点来计算收益率）\n",
    "# returns = returns.iloc[1:]\n",
    "\n",
    "# # 将收益率DataFrame保存为CSV文件\n",
    "# returns.to_csv('data/stock_returns.csv', index=True)\n",
    "# print('data/stock_returns.csv saved')\n",
    "\n",
    "# # 将收益率DataFrame保存为序列化的二进制文件（Pickle格式）\n",
    "# returns.to_pickle('data/stock_returns.pkl')\n",
    "# print('data/stock_returns.pkl saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 处理收益率 - 测试\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# 设定路径\n",
    "#path_to_stock_returns = 'data/stock_returns_test.csv'\n",
    "path_to_stock_returns = 'data/stock_returns.csv'\n",
    "\n",
    "path_to_hfq_data_folder = 'data/backward_adjust_factor/'\n",
    "\n",
    "\n",
    "\n",
    "# 读取股票回报率数据\n",
    "stock_returns = pd.read_csv(path_to_stock_returns)\n",
    "stock_returns['trade_time'] = pd.to_datetime(stock_returns['trade_time'])\n",
    "stock_returns.set_index('trade_time', inplace=True)\n",
    "\n",
    "# 遍历 stock_returns 的列\n",
    "for ticker in stock_returns.columns:  # 包括所有列\n",
    "    file_found = False\n",
    "    # 尝试找到hfq_data_path中sh+ticker.csv或者sz+ticker.csv文件\n",
    "    for prefix in ['sh', 'sz']:\n",
    "        filename = f'{prefix}{ticker}.csv'\n",
    "        file_path = os.path.join(path_to_hfq_data_folder, filename)\n",
    "        if os.path.exists(file_path):\n",
    "            hfq_data = pd.read_csv(file_path)\n",
    "            hfq_data['date'] = pd.to_datetime(hfq_data['date'])\n",
    "            file_found = True\n",
    "            break\n",
    "\n",
    "    if file_found:\n",
    "        # 遍历hfq_data中日期在2000年1月1日以后的数据\n",
    "        for index, row in hfq_data[hfq_data['date'] > '2000-01-01'].iterrows():\n",
    "            # 在日期后增加09:31:00的时间\n",
    "            trade_time = row['date'] + datetime.timedelta(hours=9, minutes=31)\n",
    "            # 处理对应的收益率数据\n",
    "            if trade_time in stock_returns.index:\n",
    "                stock_returns.at[trade_time, ticker] = (stock_returns.at[trade_time, ticker] + 1) * row['hfq_one_point'] - 1\n",
    "    else:\n",
    "        print(f'No hfq_one_point data file found for ticker {ticker}. Skipping...')\n",
    "\n",
    "# 保存处理后的数据\n",
    "#stock_returns.to_csv('data/adjusted_return_test.csv')\n",
    "stock_returns.to_csv('data/adjusted_return.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers:  13%|█▎        | 90/696 [00:02<00:11, 51.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hfq_one_point data file found for ticker 001696. Skipping...\n",
      "No hfq_one_point data file found for ticker 001872. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers:  24%|██▎       | 164/696 [00:03<00:12, 43.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hfq_one_point data file found for ticker 001914. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers: 100%|██████████| 696/696 [00:05<00:00, 117.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hfq_one_point data file found for ticker 001896. Skipping...\n"
     ]
    }
   ],
   "source": [
    "### 处理收益率\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm  # 引入tqdm库\n",
    "\n",
    "# 设定路径\n",
    "path_to_stock_returns = 'data/stock_returns.csv'\n",
    "path_to_hfq_data_folder = 'data/backward_adjust_factor/'\n",
    "\n",
    "# 读取股票回报率数据\n",
    "stock_returns = pd.read_csv(path_to_stock_returns)\n",
    "stock_returns['trade_time'] = pd.to_datetime(stock_returns['trade_time'])\n",
    "stock_returns.set_index('trade_time', inplace=True)\n",
    "\n",
    "# 使用tqdm创建进度条\n",
    "for ticker in tqdm(stock_returns.columns, desc=\"Processing tickers\"):  # 包括所有列，并添加进度条\n",
    "    file_found = False\n",
    "    # 尝试找到hfq_data_path中sh+ticker.csv或者sz+ticker.csv文件\n",
    "    for prefix in ['sh', 'sz']:\n",
    "        filename = f'{prefix}{ticker}.csv'\n",
    "        file_path = os.path.join(path_to_hfq_data_folder, filename)\n",
    "        if os.path.exists(file_path):\n",
    "            hfq_data = pd.read_csv(file_path)\n",
    "            hfq_data['date'] = pd.to_datetime(hfq_data['date'])\n",
    "            file_found = True\n",
    "            break\n",
    "\n",
    "    if file_found:\n",
    "        # 遍历hfq_data中日期在2000年1月1日以后的数据\n",
    "        for index, row in hfq_data[hfq_data['date'] > '2000-01-01'].iterrows():\n",
    "            # 在日期后增加09:31:00的时间\n",
    "            trade_time = row['date'] + datetime.timedelta(hours=9, minutes=31)\n",
    "            # 处理对应的收益率数据\n",
    "            if trade_time in stock_returns.index:\n",
    "                stock_returns.at[trade_time, ticker] = (stock_returns.at[trade_time, ticker] + 1) * row['hfq_one_point'] - 1\n",
    "    else:\n",
    "        print(f'No hfq_one_point data file found for ticker {ticker}. Skipping...')\n",
    "\n",
    "# 保存处理后的数据\n",
    "stock_returns.to_csv('data/adjusted_return.csv')\n",
    "stock_returns.to_pickle('data/stock_returns.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 合并股票日线数据\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def merge_stock_data(source_directory, output_file_path, top_stocks_file):\n",
    "    with open(top_stocks_file, 'r', encoding='utf-8') as file:\n",
    "        tickers = json.load(file)  \n",
    "    \n",
    "    merged_data = None\n",
    "    cutoff_date = pd.to_datetime('1999-01-01').date()  # 转换为 date 类型\n",
    "\n",
    "    for file in os.listdir(source_directory):\n",
    "        if file.endswith(\".csv\"):\n",
    "            stock_code = file.split('.')[0]  # 假设文件名格式为 '000001.SZ.csv'\n",
    "            stock_code_numeric = ''.join(filter(str.isdigit, stock_code))  # 提取数字部分\n",
    "            if stock_code_numeric in tickers:\n",
    "                df = pd.read_csv(\n",
    "                    os.path.join(source_directory, file),\n",
    "                    encoding='gbk',\n",
    "                    parse_dates=['交易时间'],\n",
    "                    date_parser=lambda x: pd.to_datetime(x, format='%Y%m%d').date()\n",
    "                )\n",
    "                df['交易时间'] = df['交易时间'].dt.date  # 转换为 date 类型\n",
    "                df = df[df['交易时间'] >= cutoff_date]\n",
    "                df = df[['交易时间', '收盘价']]\n",
    "                df.rename(columns={'收盘价': stock_code}, inplace=True)\n",
    "\n",
    "                if merged_data is None:\n",
    "                    merged_data = df\n",
    "                else:\n",
    "                    merged_data = pd.merge_ordered(merged_data, df, on='交易时间', how='outer', fill_method='ffill')\n",
    "\n",
    "    if merged_data is not None:\n",
    "        os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "        merged_data.to_csv(output_file_path, index=False)\n",
    "    else:\n",
    "        print(\"没有可用的数据进行合并。\")\n",
    "\n",
    "# 使用示例：\n",
    "source_directory = 'data/stocks_daily_data/'\n",
    "output_file_path = 'data/merged_daily_stock_data.csv'\n",
    "top_stocks_file = 'data/top_market_cap_stocks.json'\n",
    "merge_stock_data(source_directory, output_file_path, top_stocks_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 将日线收盘价转为收益率\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "stock_prices_path = 'data/merged_daily_stock_data.csv'\n",
    "\n",
    "stock_data = pd.read_csv(stock_prices_path)\n",
    "stock_data.set_index('trade_date', inplace=True)\n",
    "\n",
    "# 计算收益率\n",
    "stock_returns = stock_data.pct_change()\n",
    "stock_returns = stock_returns.iloc[1:]  # 去掉第一行\n",
    "stock_returns.to_csv('data/stock_returns_daily.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hfq_one_point data file found for ticker 001696. Skipping...\n",
      "No hfq_one_point data file found for ticker 001872. Skipping...\n",
      "No hfq_one_point data file found for ticker 001896. Skipping...\n",
      "No hfq_one_point data file found for ticker 001914. Skipping...\n"
     ]
    }
   ],
   "source": [
    "### 使用后复权因子调整股票日线的收益率\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# 设定路径\n",
    "path_to_stock_returns = 'data/stock_returns_daily.csv'\n",
    "path_to_hfq_data_folder = 'data/backward_adjust_factor/'\n",
    "\n",
    "# 读取股票回报率数据\n",
    "stock_returns = pd.read_csv(path_to_stock_returns)\n",
    "stock_returns['trade_date'] = pd.to_datetime(stock_returns['trade_date'])\n",
    "stock_returns.set_index('trade_date', inplace=True)\n",
    "\n",
    "\n",
    "for ticker in stock_returns.columns:  # 包括所有列\n",
    "    file_found = False\n",
    "    # 尝试找到hfq_data_path中sh+ticker.csv或者sz+ticker.csv文件\n",
    "    for prefix in ['sh', 'sz']:\n",
    "        filename = f'{prefix}{ticker}.csv'\n",
    "        file_path = os.path.join(path_to_hfq_data_folder, filename)\n",
    "        if os.path.exists(file_path):\n",
    "            hfq_data = pd.read_csv(file_path)\n",
    "            hfq_data['date'] = pd.to_datetime(hfq_data['date'])\n",
    "            file_found = True\n",
    "            break\n",
    "\n",
    "    if file_found:\n",
    "        # 遍历hfq_data中日期在2000年1月1日以后的数据\n",
    "        for index, row in hfq_data[hfq_data['date'] > '1999-01-01'].iterrows():\n",
    "            trade_time = row['date']\n",
    "            # 处理对应的收益率数据\n",
    "            if trade_time in stock_returns.index:\n",
    "                stock_returns.at[trade_time, ticker] = (stock_returns.at[trade_time, ticker] + 1) * row['hfq_one_point'] - 1\n",
    "    else:\n",
    "        print(f'No hfq_one_point data file found for ticker {ticker}. Skipping...')\n",
    "\n",
    "\n",
    "# 保存处理后的数据\n",
    "stock_returns.to_csv('data/adjusted_returns_daily.csv')\n",
    "stock_returns.to_pickle('data/stock_returns_daily.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = -1.7039907779586318e-05\n",
      "std = 0.0020668156696454104\n",
      "len = 241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trade_time\n",
       "2023-11-30 09:31:00   -0.003072\n",
       "2023-11-30 09:32:00   -0.003082\n",
       "2023-11-30 09:33:00    0.000000\n",
       "2023-11-30 09:34:00    0.006182\n",
       "2023-11-30 09:35:00   -0.001536\n",
       "                         ...   \n",
       "2023-11-30 14:56:00   -0.001550\n",
       "2023-11-30 14:57:00   -0.001553\n",
       "2023-11-30 14:58:00    0.000000\n",
       "2023-11-30 14:59:00    0.000000\n",
       "2023-11-30 15:00:00    0.007776\n",
       "Name: 600733, Length: 241, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 解释屹洲的数据问题\n",
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "file_path = 'data/stock_returns.csv'  # 这里填入文件的路径\n",
    "selected_columns = ['trade_time', '600733']  # 您希望加载的列\n",
    "\n",
    "data = pd.read_csv(file_path, usecols=selected_columns, parse_dates=['trade_time'])\n",
    "data.set_index('trade_time', inplace=True)\n",
    "sample_test = data['600733'].loc['2023-11-30']\n",
    "#sample_test = sample_test.iloc[1:]\n",
    "\n",
    "print(f\"mean = {sample_test.mean()}\")\n",
    "print(f\"std = {sample_test.std()}\")\n",
    "print(f\"len = {len(sample_test)}\")\n",
    "\n",
    "sample_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of 0s: 56650802\n",
      "Total number of elements: 194601600\n",
      "Ratio: 0.2911116969233552\n",
      "[0.36293633762517885, 0.3264842632331903, 0.18104792560801145, 0.2736409155937053, 0.38564020028612306, 0.28023247496423465, 0.25912374821173106, 0.18853719599427754, 0.19012160228898425, 0.3148068669527897, 0.2882725321888412, 0.36507510729613735, 0.276777539341917, 0.2648140200286123, 0.2719599427753934, 0.2713090128755365, 0.3057010014306152, 0.2799892703862661, 0.2526144492131617, 0.39606938483547927, 0.370225321888412, 0.21243204577968527, 0.37894134477825464, 0.360379113018598, 0.3320422031473534, 0.2840236051502146, 0.2969098712446352, 0.2662696709585122, 0.22855507868383404, 0.20133404864091559, 0.2019134477825465, 0.4369170243204578, 0.3610550786838341, 0.4320994277539342, 0.2579685264663805, 0.3624928469241774, 0.22968884120171673, 0.18221745350500715, 0.3376001430615165, 0.23331545064377682, 0.19611230329041487, 0.27108726752503576, 0.2759942775393419, 0.305, 0.3087732474964235, 0.27741058655221745, 0.35571173104434906, 0.18163805436337624, 0.30323676680972816, 0.21643061516452075, 0.2635014306151645, 0.4946459227467811, 0.32781115879828326, 0.3208011444921316, 0.27970672389127327, 0.23459227467811158, 0.3380650929899857, 0.3034084406294707, 0.20506437768240343, 0.34379113018597995, 0.27121602288984265, 0.31624105865522173, 0.41774320457796854, 0.34436337625178826, 0.324431330472103, 0.24507868383404863, 0.4551466380543634, 0.2895457796852647, 0.2559298998569385, 0.28629828326180257, 0.2935622317596567, 0.41858369098712445, 0.33129113018598, 0.3142560801144492, 0.25113376251788266, 0.34648426323319026, 0.2689771101573677, 0.357914878397711, 0.34815092989985696, 0.2970135908440629, 0.20466022889842633, 0.30142346208869814, 0.27630543633762517, 0.3044742489270386, 0.242120886981402, 0.1817238912732475, 0.30527539341917026, 0.20951716738197426, 0.31484263233190274, 0.20278969957081544, 0.24722460658082976, 0.3051788268955651, 0.2966094420600858, 0.3122567954220315, 0.2770815450643777, 0.3365379113018598, 0.3761695278969957, 0.2518311874105866, 0.18476752503576538, 0.3370350500715308, 0.32531115879828326, 0.22522532188841202, 0.18294706723891274, 0.3359155937052933, 0.20242489270386266, 0.34045779685264665, 0.2376788268955651, 0.2946173104434907, 0.3222889842632332, 0.262120886981402, 0.2598962804005722, 0.1977181688125894, 0.255532904148784, 0.3132367668097282, 0.20761444921316166, 0.24316165951359084, 0.25280042918454937, 0.32975679542203146, 0.237310443490701, 0.2930722460658083, 0.37060801144492134, 0.22206366237482117, 0.29289699570815453, 0.29123748211731043, 0.32974964234620885, 0.23417024320457797, 0.27933118741058655, 0.2332403433476395, 0.35087267525035765, 0.28253218884120174, 0.4029077253218884, 0.23064020028612303, 0.33224248927038624, 0.19769670958512162, 0.1781080114449213, 0.22644492131616595, 0.35313662374821175, 0.28756437768240345, 0.2755364806866953, 0.3357045779685265, 0.1998283261802575, 0.3578612303290415, 0.277843347639485, 0.20670243204577968, 0.154431330472103, 0.15456723891273247, 0.3040200286123033, 0.2568633762517883, 0.24567954220314736, 0.40625894134477825, 0.31295422031473535, 0.17154864091559371, 0.30435264663805434, 0.3293562231759657, 0.2872067238912733, 0.17909513590844062, 0.2944170243204578, 0.1703898426323319, 0.2390307582260372, 0.23928469241773964, 0.2301466380543634, 0.3256545064377682, 0.2095922746781116, 0.38782904148783975, 0.22816165951359085, 0.3800572246065808, 0.2653862660944206, 0.2752002861230329, 0.20912732474964235, 0.26435979971387696, 0.1703755364806867, 0.23043633762517882, 0.3526251788268956, 0.30639127324749643, 0.4724821173104435, 0.23802575107296137, 0.21112303290414877, 0.21899141630901287, 0.316362660944206, 0.24505007153075822, 0.30777539341917026, 0.2554685264663805, 0.28737839771101575, 0.20067596566523604, 0.2677753934191702, 0.26109442060085836, 0.17585836909871244, 0.20765736766809728, 0.3590844062947067, 0.24406652360515022, 0.3225429184549356, 0.27886981402002864, 0.4195922746781116, 0.20575822603719598, 0.3463125894134478, 0.29876609442060087, 0.23095135908440628, 0.29604077253218886, 0.30080829756795424, 0.28170243204577966, 0.3172961373390558, 0.13930972818311874, 0.24220314735336196, 0.23781473533619457, 0.25089055793991416, 0.21859799713876968, 0.2965772532188841, 0.2756080114449213, 0.3742882689556509, 0.24148426323319028, 0.2017310443490701, 0.19720314735336195, 0.32275393419170245, 0.43861587982832617, 0.24593347639484978, 0.23967453505007152, 0.31475321888412017, 0.4141666666666667, 0.2611623748211731, 0.25135908440629473, 0.24631258941344777, 0.34858011444921316, 0.2849499284692418, 0.19994635193133048, 0.224206008583691, 0.4667596566523605, 0.33704220314735334, 0.408447782546495, 0.2778969957081545, 0.27184549356223175, 0.18676680972818313, 0.3035872675250358, 0.14379470672389127, 0.1711266094420601, 0.31667381974248926, 0.23348712446351932, 0.16917739628040057, 0.287843347639485, 0.40242489270386267, 0.29527539341917025, 0.2753361945636624, 0.36256437768240346, 0.38290772532188844, 0.2959907010014306, 0.27258941344778254, 0.3794492131616595, 0.3117989985693848, 0.34812947067238914, 0.3705937052932761, 0.2921602288984263, 0.33640200286123034, 0.2663590844062947, 0.23113733905579398, 0.2732474964234621, 0.31432403433476397, 0.3690343347639485, 0.16816523605150216, 0.22723175965665235, 0.3787660944206009, 0.30572246065808295, 0.30003576537911303, 0.28683118741058655, 0.28494277539341917, 0.2981115879828326, 0.3065557939914163, 0.24746065808297568, 0.26243919885550787, 0.3951072961373391, 0.4774391988555079, 0.2732117310443491, 0.255379113018598, 0.32371602288984264, 0.3884907010014306, 0.18448140200286123, 0.3520386266094421, 0.36198497854077255, 0.21295422031473535, 0.28913090128755364, 0.24428469241773962, 0.3304864091559371, 0.3009728183118741, 0.2317167381974249, 0.33473891273247497, 0.37405221745350503, 0.3616666666666667, 0.3224749642346209, 0.31571530758226035, 0.24584048640915593, 0.2770672389127325, 0.3130758226037196, 0.16341201716738196, 0.3750965665236051, 0.2009656652360515, 0.272879113018598, 0.3486158798283262, 0.23187410586552218, 0.34771816881258943, 0.2801323319027182, 0.26290057224606583, 0.3433261802575107, 0.2514842632331903, 0.19282904148783978, 0.27069027181688127, 0.2835121602288984, 0.2939413447782547, 0.3011695278969957, 0.29894849785407723, 0.3481187410586552, 0.23610872675250358, 0.1417167381974249, 0.27223175965665236, 0.36006795422031473, 0.256173104434907, 0.2975250357653791, 0.47744635193133045, 0.2394098712446352, 0.24454577968526467, 0.15703862660944207, 0.31975679542203145, 0.26837267525035763, 0.2563304721030043, 0.36474248927038627, 0.356326895565093, 0.3434728183118741, 0.25912732474964234, 0.21457081545064377, 0.21876609442060085, 0.5767489270386266, 0.2584048640915594, 0.2119349070100143, 0.37972818311874107, 0.27623390557939914, 0.22639127324749642, 0.2069456366237482, 0.2423175965665236, 0.30088340486409154, 0.2679864091559371, 0.4359942775393419, 0.26956366237482116, 0.221516452074392, 0.2096638054363376, 0.23745350500715307, 0.2684370529327611, 0.2583547925608011, 0.29812231759656654, 0.20550429184549357, 0.3659656652360515, 0.2580650929899857, 0.34072603719599426, 0.2810050071530758, 0.3074606580829757, 0.35835836909871244, 0.3143633762517883, 0.4184728183118741, 0.37375178826895566, 0.3570922746781116, 0.3244420600858369, 0.2892274678111588, 0.2401967095851216, 0.44762517882689556, 0.19766809728183118, 0.2353648068669528, 0.23875894134477826, 0.2484763948497854, 0.3986874105865522, 0.25811874105865523, 0.3184871244635193, 0.3155758226037196, 0.34621959942775393, 0.2779005722460658, 0.34318311874105867, 0.4032832618025751, 0.23219241773962804, 0.3681115879828326, 0.2578576537911302, 0.33427396280400573, 0.4051931330472103, 0.1588340486409156, 0.44645922746781114, 0.3809048640915594, 0.3175071530758226, 0.3543919885550787, 0.42467095851216025, 0.3169849785407725, 0.1630793991416309, 0.28746065808297566, 0.36088340486409154, 0.22430972818311873, 0.35183476394849783, 0.30491773962804003, 0.2918454935622318, 0.3949463519313305, 0.3169849785407725, 0.3683869814020029, 0.3032689556509299, 0.3361659513590844, 0.157843347639485, 0.3624499284692418, 0.33291845493562233, 0.3757761087267525, 0.3588519313304721, 0.2034406294706724, 0.2959191702432046, 0.3155472103004292, 0.19681330472103004, 0.19361945636623748, 0.28513948497854075, 0.19158440629470672, 0.31353719599427754, 0.37398068669527895, 0.12523962804005723, 0.28988555078683836, 0.3530937052932761, 0.3121137339055794, 0.30436695278969955, 0.2651967095851216, 0.23800429184549357, 0.16418097281831187, 0.39542560801144494, 0.281706008583691, 0.33354434907010017, 0.23816165951359083, 0.39984620886981403, 0.20359084406294706, 0.24994635193133047, 0.19508226037195994, 0.23186337625178827, 0.26813662374821173, 0.31639127324749644, 0.2815307582260372, 0.3468669527896996, 0.27218168812589416, 0.3353326180257511, 0.17437410586552218, 0.27263590844062946, 0.17097997138769672, 0.30274320457796855, 0.2501859799713877, 0.4379291845493562, 0.36105150214592274, 0.33027896995708156, 0.28470314735336194, 0.2572424892703863, 0.17239628040057225, 0.2730293276108727, 0.2748569384835479, 0.3399928469241774, 0.2658082975679542, 0.25853719599427755, 0.254846208869814, 0.23200286123032904, 0.25322246065808296, 0.3892489270386266, 0.25810085836909874, 0.2710836909871245, 0.3380650929899857, 0.25805436337625176, 0.34372675250357654, 0.3280436337625179, 0.3705150214592275, 0.17473891273247497, 0.2161480686695279, 0.2875178826895565, 0.26966738197424894, 0.3575464949928469, 0.3819349070100143, 0.43766452074391987, 0.3318812589413448, 0.36322961373390555, 0.3339055793991416, 0.2689771101573677, 0.23024678111587982, 0.3147353361945637, 0.2101680972818312, 0.3041523605150215, 0.2391881258941345, 0.3317274678111588, 0.35341201716738196, 0.27973533619456364, 0.25931330472103004, 0.32125536480686695, 0.4979363376251788, 0.2243884120171674, 0.32838340486409157, 0.25494992846924175, 0.3223068669527897, 0.3586802575107296, 0.29139484978540775, 0.2430722460658083, 0.2745529327610873, 0.3151609442060086, 0.3704113018597997, 0.28377324749642346, 0.2569170243204578, 0.35553290414878397, 0.2908690987124464, 0.2785836909871245, 0.1733082975679542, 0.2575393419170243, 0.2392238912732475, 0.3311230329041488, 0.25756795422031475, 0.2711337625178827, 0.44302932761087266, 0.26261802575107296, 0.34095135908440627, 0.2576967095851216, 0.18479613733905578, 0.20527181688125895, 0.25953862660944205, 0.2413733905579399, 0.250983547925608, 0.3263698140200286, 0.15149856938483547, 0.2328683834048641, 0.33553290414878395, 0.28949213161659515, 0.39945994277539343, 0.4143919885550787, 0.2902396280400572, 0.24968884120171675, 0.23375536480686696, 0.21419527896995708, 0.3036301859799714, 0.2767381974248927, 0.27928826895565095, 0.29315450643776825, 0.19089771101573677, 0.35487839771101576, 0.2370922746781116, 0.30794706723891274, 0.2305865522174535, 0.3144384835479256, 0.4359656652360515, 0.3942846924177396, 0.2679613733905579, 0.35525035765379115, 0.3325178826895565, 0.4149248927038627, 0.20692775393419172, 0.19662017167381973, 0.23967453505007152, 0.1850321888412017, 0.2847138769670958, 0.34490343347639485, 0.28604792560801146, 0.2405793991416309, 0.2925786838340486, 0.22973533619456366, 0.32540057224606583, 0.41546137339055794, 0.30758941344778257, 0.22754649499284693, 0.2684585121602289, 0.3715021459227468, 0.29281473533619456, 0.20237124463519313, 0.27237839771101574, 0.2757832618025751, 0.1782796852646638, 0.3097818311874106, 0.5429184549356223, 0.3319849785407725, 0.23185264663805435, 0.2796745350500715, 0.337879113018598, 0.35003218884120174, 0.2875286123032904, 0.3275178826895565, 0.27943490701001433, 0.3446030042918455, 0.22687410586552217, 0.3256294706723891, 0.36755007153075825, 0.3023927038626609, 0.15375894134477824, 0.23758583690987126, 0.25643776824034337, 0.3386587982832618, 0.29793633762517885, 0.20954220314735336, 0.2674713876967096, 0.27586194563662375, 0.22853004291845494, 0.27898426323319025, 0.2607904148783977, 0.3054577968526466, 0.29124463519313304, 0.49299356223175966, 0.2576859799713877, 0.3403505007153076, 0.1965307582260372, 0.2436695278969957, 0.23587982832618026, 0.2990343347639485, 0.29746065808297567, 0.3473283261802575, 0.27705650929899855, 0.3710085836909871, 0.3173569384835479, 0.44224606580829756, 0.2892453505007153, 0.3228934191702432, 0.16792918454935624, 0.3747174535050071, 0.2917131616595136, 0.35528969957081546, 0.3245886981402003, 0.27800071530758225, 0.32196351931330475, 0.32565808297567955, 0.3459656652360515, 0.3090486409155937, 0.3373748211731044, 0.4480865522174535, 0.3822424892703863, 0.31530042918454937, 0.300568669527897, 0.30971387696709585, 0.22275751072961372, 0.32600500715307584, 0.3096423462088698, 0.28795779685264666, 0.24898783977110156, 0.30359799713876967, 0.29312947067238915, 0.23642346208869813, 0.1999785407725322, 0.32469241773962804, 0.17356223175965665, 0.41070457796852644, 0.21299356223175966, 0.32521459227467814, 0.2919635193133047, 0.23204220314735335, 0.41851931330472103, 0.27605865522174533, 0.35785765379113016, 0.3215450643776824, 0.3786480686695279, 0.28971030042918455, 0.25140915593705293, 0.19860872675250357, 0.3100250357653791, 0.29467095851216024, 0.29176680972818314, 0.4462589413447783, 0.3602110157367668, 0.24800786838340486, 0.3219420600858369, 0.16194206008583692, 0.4107367668097282, 0.3264878397711016, 0.3742024320457797, 0.24948140200286123, 0.40972818311874104, 0.2904899856938484, 0.23215307582260372, 0.25625536480686695, 0.2552503576537911, 0.3444706723891273, 0.43295422031473535, 0.20054721030042919, 0.22527539341917024, 0.31660228898426324, 0.3432796852646638, 0.3900822603719599, 0.2203826895565093, 0.46314377682403435, 0.29941344778254647, 0.3963161659513591, 0.30956008583690986, 0.31760729613733907, 0.16733905579399141, 0.2724391988555079, 0.3588125894134478, 0.2582439198855508, 0.25666666666666665, 0.2688018597997139, 0.2770815450643777, 0.19370171673819742, 0.3259585121602289, 0.256670243204578, 0.2746494992846924, 0.30552575107296137, 0.2811158798283262, 0.343898426323319, 0.35911659513590843, 0.2928290414878398, 0.3047711015736767, 0.3377002861230329, 0.2789878397711016, 0.18704577968526467, 0.3446745350500715, 0.17477110157367667, 0.2465593705293276]\n"
     ]
    }
   ],
   "source": [
    "### 计算数据中是0的比例\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'data/stock_returns_5m.csv'  # 这里填入文件的路径\n",
    "#cols_to_use = list(range(100))\n",
    "\n",
    "#df = pd.read_csv(file_path, usecols=cols_to_use)\n",
    "df = pd.read_csv(file_path)\n",
    "df.set_index('trade_time', inplace=True)\n",
    "zeros = (df == 0).sum().sum()\n",
    "total_elements = df.size\n",
    "ratio = zeros / total_elements\n",
    "\n",
    "print(f\"Total number of 0s: {zeros}\")\n",
    "print(f\"Total number of elements: {total_elements}\")\n",
    "print(f\"Ratio: {ratio}\")\n",
    "\n",
    "# 初始化一个空列表来存储每列的0比例\n",
    "zero_ratios = []\n",
    "\n",
    "# 遍历每一列\n",
    "for col in df.columns:\n",
    "    # 计算每列的0数量\n",
    "    zero_count = df[col].eq(0).sum()\n",
    "    # 计算每列的0比例\n",
    "    zero_ratio = zero_count / len(df[col])\n",
    "    # 将比例添加到列表中\n",
    "    zero_ratios.append(zero_ratio)\n",
    "\n",
    "print(zero_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to data/merged_5m__stock_data.csv\n"
     ]
    }
   ],
   "source": [
    "### 生成5min数据\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 读取CSV文件\n",
    "def filter_csv(input_file, output_file):\n",
    "    try:\n",
    "        df = pd.read_csv(input_file)\n",
    "\n",
    "        # 确保 'trade_time' 列是字符串类型\n",
    "        df['trade_time'] = df['trade_time'].astype(str)\n",
    "\n",
    "        # 筛选出分钟部分是5的倍数的行\n",
    "        df_filtered = df[df['trade_time'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S').minute % 5 == 0)]\n",
    "\n",
    "        # 保存到新的CSV文件\n",
    "        df_filtered.to_csv(output_file, index=False)\n",
    "        print(f\"Filtered data saved to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# 使用示例\n",
    "filter_csv('data/merged_data.csv', 'data/merged_5m_stock_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 将5m线收盘价转为收益率\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "stock_prices_path = 'data/merged_5m_stock_data.csv'\n",
    "\n",
    "stock_data = pd.read_csv(stock_prices_path)\n",
    "stock_data.set_index('trade_time', inplace=True)\n",
    "\n",
    "# 计算收益率\n",
    "stock_returns = stock_data.pct_change()\n",
    "stock_returns = stock_returns.iloc[1:]  # 去掉第一行\n",
    "stock_returns.to_csv('data/stock_returns_5m.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers:  24%|██▎       | 165/696 [00:00<00:00, 576.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hfq_one_point data file found for ticker 001696. Skipping...\n",
      "No hfq_one_point data file found for ticker 001872. Skipping...\n",
      "No hfq_one_point data file found for ticker 001914. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers: 100%|██████████| 696/696 [00:01<00:00, 672.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hfq_one_point data file found for ticker 001896. Skipping...\n"
     ]
    }
   ],
   "source": [
    "### 处理5m线收益率\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm  # 引入tqdm库\n",
    "\n",
    "# 设定路径\n",
    "path_to_stock_returns = 'data/stock_returns_5m.csv'\n",
    "path_to_hfq_data_folder = 'data/backward_adjust_factor/'\n",
    "\n",
    "# 读取股票回报率数据\n",
    "stock_returns = pd.read_csv(path_to_stock_returns)\n",
    "stock_returns['trade_time'] = pd.to_datetime(stock_returns['trade_time'])\n",
    "stock_returns.set_index('trade_time', inplace=True)\n",
    "\n",
    "# 使用tqdm创建进度条\n",
    "for ticker in tqdm(stock_returns.columns, desc=\"Processing tickers\"):  # 包括所有列，并添加进度条\n",
    "    file_found = False\n",
    "    # 尝试找到hfq_data_path中sh+ticker.csv或者sz+ticker.csv文件\n",
    "    for prefix in ['sh', 'sz']:\n",
    "        filename = f'{prefix}{ticker}.csv'\n",
    "        file_path = os.path.join(path_to_hfq_data_folder, filename)\n",
    "        if os.path.exists(file_path):\n",
    "            hfq_data = pd.read_csv(file_path)\n",
    "            hfq_data['date'] = pd.to_datetime(hfq_data['date'])\n",
    "            file_found = True\n",
    "            break\n",
    "\n",
    "    if file_found:\n",
    "        # 遍历hfq_data中日期在2000年1月1日以后的数据\n",
    "        for index, row in hfq_data[hfq_data['date'] > '2000-01-01'].iterrows():\n",
    "            # 在日期后增加09:35:00的时间\n",
    "            trade_time = row['date'] + datetime.timedelta(hours=9, minutes=35)\n",
    "            # 处理对应的收益率数据\n",
    "            if trade_time in stock_returns.index:\n",
    "                stock_returns.at[trade_time, ticker] = (stock_returns.at[trade_time, ticker] + 1) * row['hfq_one_point'] - 1\n",
    "    else:\n",
    "        print(f'No hfq_one_point data file found for ticker {ticker}. Skipping...')\n",
    "\n",
    "# 保存处理后的数据\n",
    "stock_returns.to_csv('data/adjusted_return_5m.csv')\n",
    "stock_returns.to_pickle('data/stock_returns_5m.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
