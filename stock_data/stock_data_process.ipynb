{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取所有股票代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the updated function to modify the filenames as required\n",
    "def get_ticker_with_prefix(path):\n",
    "    tickers = []\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.csv'):\n",
    "            # Extract numeric part\n",
    "            numeric_part = ''.join(filter(str.isdigit, f))\n",
    "            # Extract the letter part (.SZ or .SH), convert to lowercase and prepend to the numeric part\n",
    "            letter_part = f.split('.')[1].lower()\n",
    "            #ticker = letter_part + numeric_part\n",
    "            ticker = numeric_part\n",
    "            tickers.append(ticker)\n",
    "    # Sort the list of IDs\n",
    "    return sorted(tickers)\n",
    "\n",
    "# Replace 'path_to_folder' with the actual path to your folder containing the CSV files\n",
    "path_to_folder = 'data/raw-data/2024'\n",
    "\n",
    "# Get the modified stock ids\n",
    "tickers_with_prefix = get_ticker_with_prefix(path_to_folder)\n",
    "\n",
    "# Convert the list of modified stock ids to JSON format\n",
    "json_content = json.dumps(tickers_with_prefix, indent=4)\n",
    "\n",
    "# Replace 'path_to_json_file' with the actual path where you want to save the JSON file\n",
    "path_to_json_file = 'data/tickers.json'\n",
    "\n",
    "# Write the JSON content to a file\n",
    "with open(path_to_json_file, 'w') as json_file:\n",
    "    json_file.write(json_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按股票合并历年数据<多线程>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "# 路径设置\n",
    "json_file = 'data/top_cap_tickers.json'\n",
    "data_dir = 'data/raw-data/'\n",
    "merged_dir = 'data/by_stock_merged_top_caps/'\n",
    "if not os.path.exists(merged_dir):\n",
    "    os.makedirs(merged_dir)\n",
    "\n",
    "# 读取股票代码列表\n",
    "with open(json_file, 'r') as f:\n",
    "    tickers = json.load(f)\n",
    "\n",
    "def merge_data_for_ticker(ticker):\n",
    "    all_data = []  # 存储单个股票的所有数据\n",
    "    # 遍历每个年份的文件夹\n",
    "    for year in os.listdir(data_dir):\n",
    "        year_dir = os.path.join(data_dir, year)\n",
    "        if os.path.isdir(year_dir):  # 确保是目录\n",
    "            # 假设后缀可能是.SZ或.SH，尝试两种可能性\n",
    "            for suffix in ['.SZ', '.SH']:\n",
    "                file_path = os.path.join(year_dir, f\"{ticker}{suffix}.csv\")\n",
    "                if os.path.isfile(file_path):  # 确保文件存在\n",
    "                    data = pd.read_csv(file_path)\n",
    "                    all_data.append(data)\n",
    "                    break\n",
    "    \n",
    "    if all_data:\n",
    "        # 合并数据\n",
    "        merged_data = pd.concat(all_data)\n",
    "        # 按交易时间排序\n",
    "        merged_data.sort_values(by='trade_time', inplace=True)\n",
    "        # 保存到merged文件夹\n",
    "        merged_data.to_csv(os.path.join(merged_dir, f\"{ticker}.csv\"), index=False)\n",
    "\n",
    "def main():\n",
    "    max_workers = max(1, os.cpu_count() - 1)  # 保留一个CPU核心\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        executor.map(merge_data_for_ticker, tickers)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单只股票数据检查<多线程>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "def check_data_points_and_nan(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['trade_time'] = pd.to_datetime(df['trade_time'])\n",
    "    df['date'] = df['trade_time'].dt.date\n",
    "    grouped = df.groupby('date').size()\n",
    "\n",
    "    ticker = Path(file_path).stem  # 获取文件名作为股票代码\n",
    "    invalid_dates = grouped[grouped != 240].index.tolist()\n",
    "    nan_values = df.isna().any(axis=1)\n",
    "\n",
    "    if invalid_dates or nan_values.any():\n",
    "        return ticker, invalid_dates, df[nan_values]\n",
    "\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    folder_path = 'path_to_your_data_folder'  # 更改为您的数据文件夹路径\n",
    "    file_paths = Path(folder_path).glob('*.csv')\n",
    "\n",
    "    max_workers = max(1, os.cpu_count() - 1)  # 保留一个CPU核心\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = executor.map(check_data_points_and_nan, file_paths)\n",
    "        \n",
    "        for result in results:\n",
    "            if result:\n",
    "                ticker, invalid_dates, nan_data = result\n",
    "                print(f'Ticker: {ticker}, Invalid Dates: {invalid_dates}')\n",
    "                if not nan_data.empty:\n",
    "                    print(f'Non-numeric data found in Ticker: {ticker}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取历年流动性<多线程>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import akshare as ak\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "def process_stock_data(year, ticker):\n",
    "    # Prepare start and end dates\n",
    "    start_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    try:\n",
    "        # Fetch data from akshare\n",
    "        turnover = ak.stock_zh_a_hist(symbol=ticker, start_date=start_date, end_date=end_date, adjust='')[['换手率']]\n",
    "        amount = ak.stock_zh_a_hist(symbol=ticker, start_date=start_date, end_date=end_date, adjust='')[['成交额']]\n",
    "\n",
    "        if turnover.empty or amount.empty:\n",
    "            return None\n",
    "\n",
    "        trading_days = len(turnover)\n",
    "        daily_average_turnover = turnover['换手率'].mean() / 100\n",
    "        circulating_market_cap = amount['成交额'].iloc[-1] / turnover['换手率'].iloc[-1] * 100\n",
    "\n",
    "        return [ticker, daily_average_turnover, circulating_market_cap, trading_days]\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        with open('stock_data/tickers.json') as f:\n",
    "            tickers = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading tickers file: {e}\")\n",
    "        return\n",
    "\n",
    "    years = range(2000, 2024)\n",
    "    max_workers = max(1, os.cpu_count() - 1)  # 保留一个CPU核心\n",
    "\n",
    "    for year in years:\n",
    "        results = []\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = [executor.submit(process_stock_data, year, ticker) for ticker in tickers]\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    results.append(result)\n",
    "\n",
    "        if results:\n",
    "            df = pd.DataFrame(results, columns=['tickers', 'turnover_ratio', 'circulating_market_cap', 'trading_days'])\n",
    "            df.set_index('tickers', inplace=True)\n",
    "            df.sort_values(by='turnover_ratio', ascending=False, inplace=True)\n",
    "            filename = f'turnovers_{year}.csv'\n",
    "            df.to_csv(filename)\n",
    "            df.to_pickle(f'turnovers_{year}.pkl')\n",
    "            print(f\"Data for {year} saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
